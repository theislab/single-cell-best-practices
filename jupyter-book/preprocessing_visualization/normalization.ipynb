{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eceea5f9-1817-43b8-9e2f-3eb2bf8a1688",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383b510",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8bd4b6",
   "metadata": {},
   "source": [
    "Up to this point, we removed doublets and low-quality cells from the dataset and the data is available as a count matrix. These counts represent the capture, reverse transcription and sequencing of a molecule in the scRNA-seq experiment. Each of these steps adds a degree of variability to the measured count depth for identical cells, so the difference in gene expression between cells in the count data might simply be due to sampling effects. The preprocessing step of \"normalization\" addresses these problems. Several normalization techniques are used in practice varying in complexity. We would like to highlight three popular normalization techniques: proportional fitting with log plus one transformation (log1pPF), scran normalization with log plus one transformation and sctransform normalization. A complete and independent benchmark comparing all common normalization techniques is still an open research task. Attempts of comparing normalization techniques and their impact on downstream analysis tasks are either incomplete (not comparing all existing methods) or led to different conclusions {cite}`Booeshaghi2022, germain_pipecomp_2020, Crowell2020, Brown2021`. We therefore introduce the reader to log1pPF, scran and sctransform normalization and recommend to assess the results and impact of the chosen normalization technique during downstream clustering.\n",
    "\n",
    "We first import all required Python packages and load the dataset for which we removed ambient RNA, doublets and filtered low quality cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afa9c69-1dc8-4144-b2aa-48c093933185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata2ri\n",
    "import logging\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "import rpy2.rinterface_lib.callbacks as rcb\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "sc.settings.verbosity = 0\n",
    "sc.settings.set_figure_params(\n",
    "    dpi=80,\n",
    "    facecolor=\"white\",\n",
    "    # color_map=\"YlGnBu\",\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "rcb.logger.setLevel(logging.ERROR)\n",
    "ro.pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da52c05f-77a4-48f8-a45a-e8de6ab0756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to figshare afterwards\n",
    "adata = sc.read(\"s4d8_subset_gex_qc.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120db0f-8ff5-46db-bfd7-1dc49c4fc870",
   "metadata": {},
   "source": [
    "## log1p proportional fitting\n",
    "\n",
    "One common approach is equalizing the count depth for all cells with subsequent variance stabilization through log plus one (log1p) transformation. Count depth scaling normalizes the data to a “size factor” such as ten thousand (CP10k) or one million (CPM, counts per million). CPM normalization assumes that initially all cells in the dataset contained an equal number of molecules ad that the difference in count depth is only due to sampling. However, as datasets usually consist of heterogeneous cell populations which different cell sizes and molecule counts, more complex normalization methods are needed. \n",
    "\n",
    "A method similar to log1pCP10k or log1pCPM, is log1p proportional fitting (log1PF). Log1pPF describes cell depth normalization to the mean cell depth followed by log plus one transformation. This normalization technique was adapted from bulk RNA-seq. Booeshaghi et al. adujusted this normalization technique by adding another step of proportional fitting, so PFlog1pPF. They showed that PFlog1pPF\n",
    "* Effectively stabilizes variance\n",
    "* Leads to a low fraction of false-positive differentially expressed genes and\n",
    "* Recovers within cell-type Spearman correlation\n",
    "\n",
    "log1pPF and PFlog1pPF can be easily computed with scanpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8464a9a9-a31c-40e3-87b6-2da53637f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportional fitting to mean of cell depth\n",
    "proportional_fitting = sc.pp.normalize_total(adata, target_sum=None, inplace=False)\n",
    "# log1p transform\n",
    "adata.layers[\"log1pPF_normalization\"] = sc.pp.log1p(proportional_fitting[\"X\"])\n",
    "# proportional fitting\n",
    "adata.layers[\"PFlog1pPF_normalization\"] = sc.pp.normalize_total(\n",
    "    adata, target_sum=None, layer=\"log1pPF_normalization\", inplace=False\n",
    ")[\"X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b0b9a-7ee3-4979-a8e3-61de9be2e5c4",
   "metadata": {},
   "source": [
    "## scran normalization\n",
    "\n",
    "The scran method leverages a deconvolution approach. Cells are partitioned into pools and normalized across cells in each pool. The resulting system of linear equations is then used to define individual cell factors. \n",
    "\n",
    "\n",
    "We first load the additionally required Python and R packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732cada7-7346-4b03-a74f-34174a7e2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b90bcbd-0588-4709-a31f-b4d7f01848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(scran)\n",
    "library(BiocParallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947bae04-7447-413f-aac4-2d4343e43f3e",
   "metadata": {},
   "source": [
    "scran requires a coarse clustering input to improve size factor esimation performance. In this tutorial, we use a simple preprocessing approach and cluster the data at a low resolution to get an input for the size factor estimation. The basic preprocessing includes assuming all size factors are equal (library size normalization to counts per million - CPM) and log-transforming the count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129ca6f4-de7a-4f2a-8052-ad7b0ea61049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary clustering for differentiated normalisation\n",
    "adata_pp = adata.copy()\n",
    "sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6)\n",
    "sc.pp.log1p(adata_pp)\n",
    "sc.pp.pca(adata_pp, n_comps=15)\n",
    "sc.pp.neighbors(adata_pp)\n",
    "sc.tl.leiden(adata_pp, key_added=\"groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b12f01-215c-4b3a-95da-3640dac9e619",
   "metadata": {},
   "source": [
    "We now add `data_mat` and our computed groups into our R environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f89b5d3-356b-4875-91de-dfd0e09a3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "data_mat = adata_pp.X.T\n",
    "# convert to CSC if possible. See https://github.com/MarioniLab/scran/issues/70\n",
    "if scipy.sparse.issparse(data_mat):\n",
    "    if data_mat.nnz > 2**31 - 1:\n",
    "        data_mat = data_mat.tocoo()\n",
    "    else:\n",
    "        data_mat = data_mat.tocsc()\n",
    "ro.globalenv[\"data_mat\"] = data_mat\n",
    "ro.globalenv[\"input_groups\"] = adata_pp.obs[\"groups\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b2316-c2ac-4ce9-b467-1ae3ddb2882a",
   "metadata": {},
   "source": [
    "We can now also delete the copy of our anndata object, as we obtained all objects needed in order to run scran. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcb4cf1-aede-49d0-bb5c-66d9a80da0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c92ab-828b-4ad5-9ba1-2bd0cc58140f",
   "metadata": {},
   "source": [
    "We now compute the size factors based on the groups of cells we calculated before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91105ba5-9f28-43fc-95cf-9ce054df559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o size_factors\n",
    "\n",
    "size_factors = sizeFactors(\n",
    "    computeSumFactors(\n",
    "        SingleCellExperiment(\n",
    "            list(counts=data_mat)), \n",
    "            clusters = input_groups,\n",
    "            min.mean = 0.1,\n",
    "            BPPARAM = MulticoreParam()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefcc19-4a46-46e9-8f25-78485c47b3f3",
   "metadata": {},
   "source": [
    "We save `size_factors` in `.obs` and are now able to normalize the data and subsequently apply a log1p transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41375b0f-be5f-474e-85ba-c39b66e925aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"size_factors\"] = size_factors\n",
    "scran = adata.X / adata.obs[\"size_factors\"].values[:, None]\n",
    "adata.layers[\"scran_normalization\"] = csr_matrix(sc.pp.log1p(scran))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e5620-0af9-4e46-a7b0-e3932e8d47f0",
   "metadata": {},
   "source": [
    "## scTransform normalization\n",
    "\n",
    "We now introduce the reader to the normalization with *sctransform*. Sctransform was motivated by the observation that cell-to-cell variation in scRNA-seq data might be confounded by biological heterogeneity with technical effects. The method utilizes Pearson residuals from 'regularized negative binomial regression' to calculate a model of technical noise in the data. Sctransform adds the count depth as a covariate in a generalized linear model. {cite}`germain_pipecomp_2020` showed in an independent comparison of different normalization techniques that this method removed the impact of sampling effects while preserving cell heterogeneity in the dataset. Sctransform does not require downstream heuristic steps like pseudo count addition or log-transformation.\n",
    "\n",
    "The output of sctransform are normalized values that can be positive or negative. Negative residuals for a cell and gene indicate that less counts are observed than expected compared to the gene's average expression and cellular sequencing depth. Positive residuals indicate the more counts respectively.  \n",
    "\n",
    "We first load the additionally required python and R packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345ceb04-2814-46ab-85bb-e5a0a11d96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(Seurat)\n",
    "library(sctransform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09008e13-b06e-467a-a3b5-0488e3cfa0f8",
   "metadata": {},
   "source": [
    "The dataset used in this chapter has a sparse representation of the count matrix, so we sort the indices and add the AnnData object to the R environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0b53ad-ce4e-4594-8da3-29ee0ae51006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if issparse(adata.X):\n",
    "    if not adata.X.has_sorted_indices:\n",
    "        adata.X.sort_indices()\n",
    "ro.globalenv[\"adata\"] = adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c99383-5c60-47fa-9935-be16f34e56c5",
   "metadata": {},
   "source": [
    "The object is now transformed into a Seurat object with original expression annotated as \"RNA\" and we can call sctransform with the \"glmGamPoi\" method. Sctranform allows the user to only keep variable genes, we set this option to False as we are only interested in the normalization of the data. We additionally set the number of subsampling cells `ncells` to 3000 to reduce the runtime of sctransform. This number is used to build the NB regression and the default is 5000. You can adjust this number based on the compute power you have at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e3618fd-a72d-442a-b4b2-9d69369b222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "seurat_obj = as.Seurat(adata, counts=\"X\", data = NULL)\n",
    "seurat_obj = RenameAssays(seurat_obj, originalexp = \"RNA\")\n",
    "res = SCTransform(object=seurat_obj, method = \"glmGamPoi\", return.only.var.genes = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a2b76-4626-4987-9ae8-13692c657016",
   "metadata": {},
   "source": [
    "Sctransform stores the result in the \"SCT\" assay in the Seurat object. The \"SCT\" assay contains the following matrices:\n",
    "\n",
    "* `res[[\"SCT\"]]@scale.data` stores the normalized values, the residuals, which can be used as input to PCA. This matrix is non-sparse so it is rather memory-costly for all genes. By setting the argument `return.only.var.genes` to `TURE` we can save memory and sctransform will only store variable genes. However, in this case the sctransform feature selection method is used and {cite}`germain_pipecomp_2020` recommend to use deviance as stated in the following chapter.\n",
    "\n",
    "* sctransform additionally stored the 'corrected' UMI counts which can be interpreted as the number of counts one would observe if all cells were sequenced to the same depth. They are stored in `res[[\"SCT\"]]@counts`.\n",
    "\n",
    "* `res[[\"SCT\"]]@data` contains a log-normalized version of the corrected counts. They may be helpful for visualization, differential expression analysis and integration. Generally, sctransform recommends to use the residuals directly for downstream tasks.\n",
    "\n",
    "We now extract the residuals and save it to the AnnData object. As `sctransform` returns a gene by cell matrix, we transpose it and save it as a new layer. The residuals can then be used for further downstream analysis steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ba18d0-038e-414b-b8cf-55da78058876",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x = ro.r(\"res@assays$SCT@scale.data\").T\n",
    "adata.layers[\"scTransform_normalization\"] = norm_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc1569-27d0-453c-aaf9-08847a87a10d",
   "metadata": {},
   "source": [
    "We applied different normalization techniques to our dataset and saved them as separat layers to our anndata object. Depending on the downstream analysis task it can be favourable to use a differently normalized layer and assess the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e33d217e-6c5c-45ac-9ed9-e1a73ccb5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"s4d8_subset_gex_qc_norm.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7c0d3",
   "metadata": {},
   "source": [
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b794b",
   "metadata": {},
   "source": [
    "1. Try a simply normalization technique like log1pPF and assess normlaization result by visualizing it on a UMAP with respect to total counts and highly expressed genes in your dataset.\n",
    "2. Try scran normalization and assess if rare cell populations can be still recovered. \n",
    "3. If rare cell populations are removed with scran normalization, try scTransform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28855f58-cda0-4280-b8e9-23bfbfe4be72",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
