{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Summary\n",
    "\n",
    "- Interoperabilty between languages allows analysts to take advantage of the strengths of different ecosystems\n",
    "- On-disk interoperability uses standard file formats to transfer data and is typically more reliable\n",
    "- In-memory interoperabilty transfers data directly between parallel sessions and is convenient for interactive analysis\n",
    "- While interoperability is currently possible developers continue to improve the experience\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have discussed in the {ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>` there are three main ecosystems for single-cell analysis, the [Bioconductor](https://bioconductor.org/) and [Seurat](https://satijalab.org/seurat/index.html) ecosystems in R and the Python-based [scverse](https://scverse.org/) ecosystem. A common question from new analysts is which ecosystem they should focus on learning and using? While it makes sense to focus on one to start with, and a successful standard analysis can be performed in any ecosystem, we promote the idea that competent analysts should be familiar with all three ecosystems and comfortable moving between them. This approach allows analysts to use the best-performing tools and methods regardless of how they were implemented. When analysts are not comfortable moving between ecosystems they often tend to use packages that are easy to access, even when they have been shown to have shortcomings compared to packages in another ecosystem. The ability of analysts to move between ecosystems allows developers to take advantage of the different strengths of programming languages. For example, R has strong inbuilt support for complex statistical modelling while the majority of deep learning libraries are focused on Python. By supporting common on-disk data formats and in-memory data structures developers can be confident that analysts can access their package and can use the platform the platform that is most appropriate for their method. Another motivation for being comfortable with multiple ecosystems is the accessibility and availability of data, results and documentation. Often data or results are only made available in one format and analysts will need to be familiar with that format in order to access it. A basic understanding of other ecosystems is also necessary to understand package documentation and tutorials when deciding which methods to use.\n",
    "\n",
    "While we encourage analysts to be comfortable with all the major ecosystems, moving between them is only possible when they are interoperable. Thankfully, lots of work has been done in this area and it is now relatively simple in most cases using standard packages. In this chapter, we discuss the various ways data can be moved between ecosystems via disk or in-memory, the differences between them and their advantages. We focus on single-modality data and moving between R and Python as these are the most common cases but we also touch on multimodal data and other languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomenclature\n",
    "\n",
    "Because talking about different languages can get confusing we try to use the following conventions:\n",
    "\n",
    "- **{package}** - An R package\n",
    "- `package::function()` - A function in an R package\n",
    "- **package** - A Python package\n",
    "- `package.function()` - A function in a Python package\n",
    "- **Emphasised** - Some other important concept\n",
    "- `code` - Other parts of code including objects, variables etc. This is also used for files or directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy\n",
    "import scanpy\n",
    "import mudata\n",
    "import tempfile\n",
    "import os\n",
    "import rpy2.robjects\n",
    "import anndata2ri\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "anndata2ri.activate()\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk-based interoperability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach to moving between languages is via disk-based interoperability. This involves writing a file to disk in one language and then reading that file into a second language. In many cases, this approach is simpler, more reliable and scalable than in-memory interoperability (which we discuss below) but it comes at the cost of greater storage requirements and reduced interactivity. Disk-based interoperability tends to work particularly well when there are established processes for each stage of analysis and you want to pass objects from one to the next (especially as part of a pipeline developed using a workflow manager such as [NextFlow](https://www.nextflow.io/index.html) or [snakemake](https://snakemake.readthedocs.io/en/stable/)). However, disk-based interoperability is less convenient for interactive steps such as data exploration or experimenting with methods as you need to write a new file whenever you want to move between languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing file formats specifically developed for single-cell data we want to briefly mention that common simple text file formats (such as CSV, TSV, JSON etc.) can often be the answer to transferring data between languages. They work well in cases where some analysis has been performed and what you want to transfer is a subset of the information about an experiment. For example, you may want to transfer only the cell metadata but do not require the feature metadata, expression matrices etc. The advantage of using simple text formats is that they are well supported by almost any language and do not require single-cell specific packages. However, they can quickly become impractical as what you want to transfer becomes more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5-based formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common disk formats for single-cell data are based on [Hierarchical Data Format version 5](https://www.hdfgroup.org/solutions/hdf5/) or HDF5. This is an open-source file format designed for storing large, complex and heterogeneous data. It has a file directory type structure (similar to how files and folders are organised on your computer) which allows many different kinds of data to be stored in a single file with an arbitrarily complex hierarchy. While this format is very flexible, to properly interact with it you need to know where and how the different information is stored. For this reason, standard specifications for storing single-cell data in HDF5 files have been developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H5AD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H5AD format is the HDF5 disk representation of the `AnnData` object used by scverse packages and is commonly used to share single-cell datasets. As it is part of the scverse ecosystem, reading and writing these files from Python is well-supported and is part of the core functionality of the [**anndata** package](https://anndata.readthedocs.io/en/latest/index.html) (read more about the format [here](https://anndata.readthedocs.io/en/latest/fileformat-prose.html)).\n",
    "\n",
    "To demonstrate interoperability we will use a small, randomly generated dataset that has gone through some of the steps of a standard analysis workflow to populate the various slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 100 × 2000\n",
       "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
       "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a randomly generated AnnData object to use as an example\n",
    "counts = csr_matrix(numpy.random.poisson(1, size=(100, 2000)), dtype=numpy.float32)\n",
    "adata = anndata.AnnData(counts)\n",
    "adata.obs_names = [f\"Cell_{i:d}\" for i in range(adata.n_obs)]\n",
    "adata.var_names = [f\"Gene_{i:d}\" for i in range(adata.n_vars)]\n",
    "# Do some standard processing to populate the object\n",
    "scanpy.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "scanpy.pp.normalize_total(adata, inplace=True)\n",
    "scanpy.pp.log1p(adata)\n",
    "scanpy.pp.highly_variable_genes(adata, inplace=True)\n",
    "scanpy.tl.pca(adata)\n",
    "scanpy.pp.neighbors(adata)\n",
    "scanpy.tl.umap(adata)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write this mock object to disk as a H5AD file to demonstrate how those files can be read from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "h5ad_file = os.path.join(temp_dir.name, \"example.h5ad\")\n",
    "\n",
    "adata.write_h5ad(h5ad_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several packages exist for reading and writing H5AD files from R. While they result in a file on disk these packages usually rely on wrapping the Python **anndata** package to handle the actual reading and writing of files with an in-memory conversion step to convert between R and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with Bioconductor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Bioconductor **{zellkonverter}** package](https://bioconductor.org/packages/zellkonverter/) helps makes this easier by using the [**{basilisk}** package](https://bioconductor.org/packages/basilisk/) to manage creating an appropriate Python environment. If that all sounds a bit technical, the end result is that Bioconductor users can read and write H5AD files using commands like below without requiring any knowledge of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, because of the way this book is made, we are unable to run the code directly here. Instead, we will show the code and what the output looks like when run in an R session:\n",
    "\n",
    "```r\n",
    "sce <- zellkonverter::readH5AD(h5ad_file, verbose = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "ℹ Using the Python reader\n",
    "ℹ Using anndata version 0.8.0\n",
    "✔ Read /.../luke.zappia/Downloads/example.h5ad [113ms]\n",
    "✔ uns$hvg$flavor converted [17ms]\n",
    "✔ uns$hvg converted [50ms]\n",
    "✔ uns$log1p converted [25ms]\n",
    "✔ uns$neighbors converted [18ms]\n",
    "✔ uns$pca$params$use_highly_variable converted [16ms]\n",
    "✔ uns$pca$params$zero_center converted [16ms]\n",
    "✔ uns$pca$params converted [80ms]\n",
    "✔ uns$pca$variance converted [17ms]\n",
    "✔ uns$pca$variance_ratio converted [16ms]\n",
    "✔ uns$pca converted [184ms]\n",
    "✔ uns$umap$params$a converted [16ms]\n",
    "✔ uns$umap$params$b converted [16ms]\n",
    "✔ uns$umap$params converted [80ms]\n",
    "✔ uns$umap converted [112ms]\n",
    "✔ uns converted [490ms]\n",
    "✔ Converting uns to metadata ... done\n",
    "✔ X matrix converted to assay [29ms]\n",
    "✔ layers$counts converted [27ms]\n",
    "✔ Converting layers to assays ... done\n",
    "✔ var converted to rowData [25ms]\n",
    "✔ obs converted to colData [24ms]\n",
    "✔ varm$PCs converted [18ms]\n",
    "✔ varm converted [47ms]\n",
    "✔ Converting varm to rowData$varm ... done\n",
    "✔ obsm$X_pca converted [15ms]\n",
    "✔ obsm$X_umap converted [16ms]\n",
    "✔ obsm converted [80ms]\n",
    "✔ Converting obsm to reducedDims ... done\n",
    "ℹ varp is empty and was skipped\n",
    "✔ obsp$connectivities converted [22ms]\n",
    "✔ obsp$distances converted [23ms]\n",
    "✔ obsp converted [92ms]\n",
    "✔ Converting obsp to colPairs ... done\n",
    "✔ SingleCellExperiment constructed [164ms]\n",
    "ℹ Skipping conversion of raw\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "```\n",
    "\n",
    "Because we have turned on the verbose output you can see how **{zellkonverter}** reads the file using Python and converts each part of the `AnnData` object to a Bioconductor `SingleCellExperiment` object. We can see what the result looks like:\n",
    "\n",
    "```r\n",
    "sce\n",
    "```\n",
    "\n",
    "```\n",
    "class: SingleCellExperiment\n",
    "dim: 2000 100\n",
    "metadata(5): hvg log1p neighbors pca umap\n",
    "assays(2): X counts\n",
    "rownames(2000): Gene_0 Gene_1 ... Gene_1998 Gene_1999\n",
    "rowData names(11): n_cells_by_counts mean_counts ... dispersions_norm\n",
    "  varm\n",
    "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
    "colData names(8): n_genes_by_counts log1p_n_genes_by_counts ...\n",
    "  pct_counts_in_top_200_genes pct_counts_in_top_500_genes\n",
    "reducedDimNames(2): X_pca X_umap\n",
    "mainExpName: NULL\n",
    "altExpNames(0):\n",
    "```\n",
    "\n",
    "This object can then be used as normal by any Bioconductor package. If we want to write a new H5AD file we can use the `writeH5AD()` function:\n",
    "\n",
    "```r\n",
    "zellkonverter_h5ad_file <- tempfile(fileext = \".h5ad\")\n",
    "zellkonverter::writeH5AD(sce, zellkonverter_h5ad_file, verbose = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "ℹ Using anndata version 0.8.0\n",
    "ℹ Using the 'X' assay as the X matrix\n",
    "✔ Selected X matrix [29ms]\n",
    "✔ assays$X converted to X matrix [50ms]\n",
    "✔ additional assays converted to layers [30ms]\n",
    "✔ rowData$varm converted to varm [28ms]\n",
    "✔ reducedDims converted to obsm [68ms]\n",
    "✔ metadata converted to uns [24ms]\n",
    "ℹ rowPairs is empty and was skipped\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "✔ Wrote '/.../.../rj/.../T/.../file102cfa97cc51.h5ad ' [133ms]\n",
    "```\n",
    "\n",
    "We can then read this file in Python:\n",
    "\n",
    "```python\n",
    "scanpy.read_h5ad(zellkonverter_h5ad_file)\n",
    "```\n",
    "\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'X_name', 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this the first time that you run a **{zellkonverter}** function you will see that it first creates a special conda environment to use (which can take a while). Once that environment exists it will be re-used by following function calls. **{zellkonverter}** has additional options such as allowing you to selectively read or write parts for an object. Please refer to the package documentation for more details. Similar functionality for writing a `SingleCellExperimentObject` to an H5AD file can be found in the [**{sceasy}** package](https://github.com/cellgeni/sceasy). While these packages are effective, wrapping Python requires some overhead which should be addressed by native R H5AD writers/readers in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with **{Seurat}**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between a `Seurat` object and an H5AD file is a two-step process [as suggested by this tutorial](https://mojaveazure.github.io/seurat-disk/articles/convert-anndata.html). Firstly H5AD file is converted to a H5Seurat file (a custom HDF5 format for `Seurat` objects) using the [**{SeuratDisk}** package](https://mojaveazure.github.io/seurat-disk/) and then this file is read as a `Seurat` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Converting H5AD to H5Seurat...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: The legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\n",
      "which was just loaded, will retire in October 2023.\n",
      "Please refer to R-spatial evolution reports for details, especially\n",
      "https://r-spatial.org/r/2023/05/15/evolution4.html.\n",
      "It may be desirable to make the sf package available;\n",
      "package maintainers should consider adding sf to Suggests:.\n",
      "The sp package is now running under evolution status 2\n",
      "     (status 2 uses the sf package in place of rgdal)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Registered S3 method overwritten by 'SeuratDisk':\n",
      "  method            from  \n",
      "  as.sparse.H5Group Seurat\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Unknown file type: h5ad\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  'assay' not set, setting to 'RNA'\n",
      "\n",
      "R[write to console]: Creating h5Seurat file for version 3.1.5.9900\n",
      "\n",
      "R[write to console]: Adding X as data\n",
      "\n",
      "R[write to console]: Adding X as counts\n",
      "\n",
      "R[write to console]: Adding meta.features from var\n",
      "\n",
      "R[write to console]: Adding X_pca as cell embeddings for pca\n",
      "\n",
      "R[write to console]: Adding X_umap as cell embeddings for umap\n",
      "\n",
      "R[write to console]: Adding PCs as feature loadings fpr pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for pca\n",
      "\n",
      "R[write to console]: Adding standard deviations for pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for umap\n",
      "\n",
      "R[write to console]: Adding hvg to miscellaneous data\n",
      "\n",
      "R[write to console]: Adding log1p to miscellaneous data\n",
      "\n",
      "R[write to console]: Adding layer counts as data in assay counts\n",
      "\n",
      "R[write to console]: Adding layer counts as counts in assay counts\n",
      "\n",
      "R[write to console]: Reading H5Seurat...\n",
      "\n",
      "R[write to console]: Validating h5Seurat file\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
      "\n",
      "R[write to console]: Initializing RNA with data\n",
      "\n",
      "R[write to console]: Adding counts for RNA\n",
      "\n",
      "R[write to console]: Adding feature-level metadata for RNA\n",
      "\n",
      "R[write to console]: Adding reduction pca\n",
      "\n",
      "R[write to console]: Adding cell embeddings for pca\n",
      "\n",
      "R[write to console]: Adding feature loadings for pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for pca\n",
      "\n",
      "R[write to console]: Adding reduction umap\n",
      "\n",
      "R[write to console]: Adding cell embeddings for umap\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for umap\n",
      "\n",
      "R[write to console]: Adding command information\n",
      "\n",
      "R[write to console]: Adding cell-level metadata\n",
      "\n",
      "R[write to console]: Read Seurat object:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "2000 features across 100 samples within 1 assay \n",
      "Active assay: RNA (2000 features, 0 variable features)\n",
      " 2 dimensional reductions calculated: pca, umap\n"
     ]
    }
   ],
   "source": [
    "%%R -i h5ad_file\n",
    "\n",
    "message(\"Converting H5AD to H5Seurat...\")\n",
    "SeuratDisk::Convert(h5ad_file, dest = \"h5seurat\", overwrite = TRUE)\n",
    "message(\"Reading H5Seurat...\")\n",
    "h5seurat_file <- gsub(\".h5ad\", \".h5seurat\", h5ad_file)\n",
    "seurat <- SeuratDisk::LoadH5Seurat(h5seurat_file, assays = \"RNA\")\n",
    "message(\"Read Seurat object:\")\n",
    "seurat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because the structure of a `Seurat` object is quite different from `AnnData` and `SingleCellExperiment` objects the conversion process is more complex. See the [documentation of the conversion function](https://mojaveazure.github.io/seurat-disk/reference/Convert.html) for more details on how this is done.\n",
    "\n",
    "The **{sceasy}** package also provides a function for reading H5AD files as `Seurat` or `SingleCellExperiment` objects in a single step. **{sceasy}** also wraps Python functions but unlike **{zellkonverter}** it doesn't use a special Python environment. This means you need to be responsible for setting up the environment, making sure that R can find it and that the correct packages are installed (again, this code is not run here)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "sceasy_seurat <- sceasy::convertFormat(h5ad_file, from=\"anndata\", to=\"seurat\")\n",
    "sceasy_seurat\n",
    "```\n",
    "```\n",
    "Warning: Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
    "X -> counts\n",
    "An object of class Seurat\n",
    "2000 features across 100 samples within 1 assay\n",
    "Active assay: RNA (2000 features, 0 variable features)\n",
    " 2 dimensional reductions calculated: pca, umap\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with **{anndata}**\n",
    "\n",
    "The R [**{anndata}** package](https://anndata.dynverse.org/index.html) can also be used to read H5AD files. However, unlike the packages above it does not convert to a native R object. Instead it provides an R interface to the Python object. This is useful for accessing the data but few analysis packages will accept this as input so further in-memory conversion is usually required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Loom file format](http://loompy.org/) is an older HDF5 specification for omics data. Unlike H5AD, it is not linked to a specific analysis ecosystem, although the structure is similar to `AnnData` and `SingleCellExperiment` objects. Packages implementing the Loom format exist for both [R](https://github.com/mojaveazure/loomR) and [Python](https://pypi.org/project/loompy/) as well as a [Bioconductor package](https://bioconductor.org/packages/LoomExperiment/) for writing Loom files. However, it is often more convenient to use the higher-level interfaces provided by the core ecosystem packages. Apart from sharing datasets another common place Loom files are encountered is when spliced/unspliced reads are quantified using [velocyto](http://velocyto.org/) for {ref}`RNA velocity analysis <trajectories:rna-velocity>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another file format you may see used to share single-cell datasets is the RDS format. This is a binary format used to serialise arbitrary R objects (similar to Python Pickle files). As `SingleCellExperiment` and `Seurat` objects did not always have matching on-disk representations RDS files are sometimes used to share the results from R analyses. While this is ok within an analysis project we discourage its use for sharing data publicly or with collaborators due to the lack of interoperability with other ecosystems. Instead, we recommend using one of the HDF5 formats mentioned above that can be read from multiple languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New on-disk formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While HDF5-based formats are currently the standard for on-disk representations of single-cell data other newer technologies such as [Zarr](https://zarr.dev/) and [TileDB](https://tiledb.com/) have some advantages, particularly for very large datasets and other modalities. We expect specifications to be developed for these formats in the future which may be adopted by the community (**anndata** already provides support for Zarr files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-memory interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach to interoperability is to work on in-memory representations of an object. This approach involves active sessions from two programming languages running at the same time and either accessing the same object from both or converting between them as needed. Usually, one language acts as the main environment and there is an interface to the other language. This can be very useful for interactive analysis as it allows an analyst to work in two languages simultaneously. It is also often used when creating documents that use multiple languages (such as this book). However, in-memory interoperability has some drawbacks as it requires the analyst to be familiar with setting up and using both environments, more complex objects are often not supported by both languages and there is a greater memory overhead as data can easily become duplicated (making it difficult to use for larger datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interoperability between R ecosystems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at in-memory interoperability between R and Python first let’s consider the simpler case of converting between the two R ecosystems. The **{Seurat}** package provides functions for performing this conversion [as described in this vignette](https://satijalab.org/seurat/articles/conversion_vignette.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: SingleCellExperiment \n",
      "dim: 2000 100 \n",
      "metadata(0):\n",
      "assays(2): X logcounts\n",
      "rownames(2000): Gene-0 Gene-1 ... Gene-1998 Gene-1999\n",
      "rowData names(0):\n",
      "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
      "colData names(9): n_genes_by_counts log1p_n_genes_by_counts ...\n",
      "  pct_counts_in_top_500_genes ident\n",
      "reducedDimNames(2): PCA UMAP\n",
      "mainExpName: NULL\n",
      "altExpNames(0):\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sce_from_seurat <- Seurat::as.SingleCellExperiment(seurat)\n",
    "sce_from_seurat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "2000 features across 100 samples within 1 assay \n",
      "Active assay: RNA (2000 features, 0 variable features)\n",
      " 2 dimensional reductions calculated: PCA, UMAP\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "seurat_from_sce <- Seurat::as.Seurat(sce_from_seurat)\n",
    "seurat_from_sce\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difficult part here is due to the differences between the structures of the two objects. It is important to make sure the arguments are set correctly so that the conversion functions know which information to convert and where to place it.\n",
    "\n",
    "In many cases it may not be necessary to convert a `Seurat` object to a `SingleCellExperiment`. This is because many of the core Bioconductor packages for single-cell analysis have been designed to also accept a matrix as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 x 10 sparse Matrix of class \"dgCMatrix\"\n",
      "                                                                       \n",
      " [1,] 602.1263 622.1264  600.5326 1416.439   .         .       965.8600\n",
      " [2,] 602.1263   .         .       613.435 618.2562  943.8910  609.1107\n",
      " [3,] 602.1263 982.8946 1202.6879  969.506 618.2562  943.8910 1219.1005\n",
      " [4,]   .        .       600.5326  613.435 976.3175  594.3451    .     \n",
      " [5,] 602.1263 622.1264    .      1221.384 618.2562  594.3451  609.1107\n",
      " [6,] 954.8394 982.8946 1202.6879  613.435 618.2562  943.8910 1219.1005\n",
      " [7,] 954.8394 622.1264  952.6379  613.435 618.2562    .       965.8600\n",
      " [8,]   .      982.8946    .         .     618.2562  594.3451    .     \n",
      " [9,] 954.8394   .       600.5326  613.435   .      1192.4227 1219.1005\n",
      "[10,] 954.8394 622.1264  952.6379  613.435 618.2562  943.8910  609.1107\n",
      "                                  \n",
      " [1,]  958.4081 599.5090  610.1969\n",
      " [2,]  958.4081 952.2526  610.1969\n",
      " [3,]    .        .       965.9120\n",
      " [4,]    .        .         .     \n",
      " [5,]  605.0013 952.2526    .     \n",
      " [6,]    .        .         .     \n",
      " [7,]  605.0013 599.5090  965.9120\n",
      " [8,] 1209.0169   .       965.9120\n",
      " [9,]    .      599.5090 1413.3168\n",
      "[10,] 1209.0169   .       610.1969\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# Calculate Counts Per Million using the Bioconductor scuttle package\n",
    "# with a matrix in a Seurat object\n",
    "cpm <- scuttle::calculateCPM(Seurat::GetAssayData(seurat, slot = \"counts\"))\n",
    "cpm[1:10, 1:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is important to be sure you are accessing the right information and storing any results in the correct place if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing R from Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python interface to R is provided by the [**rpy2** package](https://rpy2.github.io/doc/latest/html/index.html). This allows you to access R functions and objects from Python. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 126146 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_mat = adata.layers[\"counts\"].T\n",
    "rpy2.robjects.globalenv[\"counts_mat\"] = counts_mat\n",
    "cpm = rpy2.robjects.r(\"scuttle::calculateCPM(counts_mat)\")\n",
    "cpm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Python objects (lists, matrices, `DataFrame`s etc.) can also be passed to R.\n",
    "\n",
    "If you are using a Jupyter notebook (as we are for this book) you can use the IPython magic interface to create cells with native R code (passing objects as required). For example, starting a cell with `%%R -i input -o output` says to take `input` as input, run R code and then return `output` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i counts_mat -o magic_cpm\n",
    "# R code running using IPython magic\n",
    "magic_cpm <- scuttle::calculateCPM(counts_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 126146 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python code accessing the results\n",
    "magic_cpm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the approach you will most commonly see in later chapters. For more information about using **rpy2** please refer to [the documentation](https://rpy2.github.io/doc/latest/html/index.html).\n",
    "\n",
    "To work with single-cell data in this way the [**anndata2ri** package](https://icb-anndata2ri.readthedocs-hosted.com/en/latest/) is especially useful. This is an extension to **rpy2** which allows R to see `AnnData` objects as `SingleCellExperiment` objects. This avoids unnecessary conversion and makes it easy to run R code on a Python object. It also enables the conversion of sparse **scipy** matrices like we saw above.\n",
    "\n",
    "In this example, we pass an `AnnData` object in the Python session to R which views it as a `SingleCellExperiment` that can be used by R functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke.zappia/miniconda3/envs/interoperability2/lib/python3.9/functools.py:888: NotConvertedWarning: Conversion 'py2rpy' not defined for objects of type '<class 'NoneType'>'\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sum detected total\n",
      "Cell_0 2005     1274  2005\n",
      "Cell_1 1941     1233  1941\n",
      "Cell_2 2011     1270  2011\n",
      "Cell_3 1947     1268  1947\n",
      "Cell_4 1933     1265  1933\n",
      "Cell_5 2031     1289  2031\n"
     ]
    }
   ],
   "source": [
    "%%R -i adata\n",
    "qc <- scuttle::perCellQCMetrics(adata)\n",
    "head(qc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you will still run into issues if an object (or part of it) cannot be interfaced correctly (for example if there is an unsupported data type). In that case, you may need to modify your object first before it can be accessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Python from R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Python from an R session is similar to accessing R from Python but here the interface is provided by the [**{reticulate}** package](https://rstudio.github.io/reticulate/). Once it is loaded we can access Python functions and objects from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List (26 items)\n",
      "<zip object at 0x18a243040>\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "reticulate_list <- reticulate::r_to_py(LETTERS)\n",
    "print(reticulate_list)\n",
    "py_builtins <- reticulate::import_builtins()\n",
    "py_builtins$zip(letters, LETTERS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working in an [RMarkdown](https://rmarkdown.rstudio.com/) or [Quarto](https://quarto.org/) document you can also write native Python chunks using the **{reticulate}** Python engine. When we do this we can use the magic `r` and `py` variables to access objects in the other language (the following code is an example that is not run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "```{r}\n",
    "# An R chunk that accesses a Python object\n",
    "print(py$py_object)\n",
    "```\n",
    "\n",
    "```{python}\n",
    "# A Python chunk that accesses an R object\n",
    "print(r$r_object)\n",
    "```\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike **anndata2ri**, there are no R packages that provide a direct interface for Python to view `SingleCellExperiment` or `Seurat` objects as `AnnData` objects.  However, we can still access most parts of an `AnnData` using **{reticulate}** (this code is not run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Print an AnnData object in a Python environment\n",
    "py$adata\n",
    "```\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```\n",
    "```r\n",
    "# Alternatively use the Python anndata package to read a H5AD file\n",
    "anndata <- reticulate::import(\"anndata\")\n",
    "anndata$read_h5ad(h5ad_file)\n",
    "```\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```\n",
    "```r\n",
    "# Access the obs slot, pandas DataFrames are automatically converted to R data.frames\n",
    "head(adata$obs)\n",
    "```\n",
    "```\n",
    "       n_genes_by_counts log1p_n_genes_by_counts total_counts\n",
    "Cell_0              1246                7.128496         1965\n",
    "Cell_1              1262                7.141245         2006\n",
    "Cell_2              1262                7.141245         1958\n",
    "Cell_3              1240                7.123673         1960\n",
    "Cell_4              1296                7.167809         2027\n",
    "Cell_5              1231                7.116394         1898\n",
    "       log1p_total_counts pct_counts_in_top_50_genes\n",
    "Cell_0           7.583756                  10.025445\n",
    "Cell_1           7.604396                   9.521436\n",
    "Cell_2           7.580189                   9.959142\n",
    "Cell_3           7.581210                   9.183673\n",
    "Cell_4           7.614805                   9.718796\n",
    "Cell_5           7.549083                  10.168599\n",
    "       pct_counts_in_top_100_genes pct_counts_in_top_200_genes\n",
    "Cell_0                    17.65903                    30.89059\n",
    "Cell_1                    16.99900                    29.71087\n",
    "Cell_2                    17.62002                    30.28601\n",
    "Cell_3                    16.83673                    30.45918\n",
    "Cell_4                    17.11889                    30.04440\n",
    "Cell_5                    18.07165                    30.29505\n",
    "       pct_counts_in_top_500_genes\n",
    "Cell_0                    61.42494\n",
    "Cell_1                    59.62114\n",
    "Cell_2                    60.92952\n",
    "Cell_3                    61.07143\n",
    "Cell_4                    59.64480\n",
    "Cell_5                    61.48577\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above the R **{anndata}** package provides an R interface for `AnnData` objects but it is not currently used by many analysis packages.\n",
    "\n",
    "For more complex analysis that requires a whole object to work on it may be necessary to completely convert an object from R to Python (or the opposite). This is not memory efficient as it creates a duplicate of the data but it does provide access to a greater range of packages. The **{zellkonverter}** package provides a function for doing this conversion (note that, unlike the function for reading H5AD files, this uses the normal Python environment rather than a specially created one) (code not run). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Convert an AnnData to a SingleCellExperiment\n",
    "sce <- zellkonverter::AnnData2SCE(adata, verbose = TRUE)\n",
    "sce\n",
    "```\n",
    "```\n",
    "✔ uns$hvg$flavor converted [21ms]\n",
    "✔ uns$hvg converted [62ms]\n",
    "✔ uns$log1p converted [22ms]\n",
    "✔ uns$neighbors converted [21ms]\n",
    "✔ uns$pca$params$use_highly_variable converted [22ms]\n",
    "✔ uns$pca$params$zero_center converted [31ms]\n",
    "✔ uns$pca$params converted [118ms]\n",
    "✔ uns$pca$variance converted [17ms]\n",
    "✔ uns$pca$variance_ratio converted [17ms]\n",
    "✔ uns$pca converted [224ms]\n",
    "✔ uns$umap$params$a converted [15ms]\n",
    "✔ uns$umap$params$b converted [17ms]\n",
    "✔ uns$umap$params converted [80ms]\n",
    "✔ uns$umap converted [115ms]\n",
    "✔ uns converted [582ms]\n",
    "✔ Converting uns to metadata ... done\n",
    "✔ X matrix converted to assay [44ms]\n",
    "✔ layers$counts converted [29ms]\n",
    "✔ Converting layers to assays ... done\n",
    "✔ var converted to rowData [37ms]\n",
    "✔ obs converted to colData [23ms]\n",
    "✔ varm$PCs converted [18ms]\n",
    "✔ varm converted [49ms]\n",
    "✔ Converting varm to rowData$varm ... done\n",
    "✔ obsm$X_pca converted [17ms]\n",
    "✔ obsm$X_umap converted [17ms]\n",
    "✔ obsm converted [80ms]\n",
    "✔ Converting obsm to reducedDims ... done\n",
    "ℹ varp is empty and was skipped\n",
    "✔ obsp$connectivities converted [21ms]\n",
    "✔ obsp$distances converted [22ms]\n",
    "✔ obsp converted [89ms]\n",
    "✔ Converting obsp to colPairs ... done\n",
    "✔ SingleCellExperiment constructed [241ms]\n",
    "ℹ Skipping conversion of raw\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "class: SingleCellExperiment\n",
    "dim: 2000 100\n",
    "metadata(5): hvg log1p neighbors pca umap\n",
    "assays(2): X counts\n",
    "rownames(2000): Gene_0 Gene_1 ... Gene_1998 Gene_1999\n",
    "rowData names(11): n_cells_by_counts mean_counts ... dispersions_norm\n",
    "  varm\n",
    "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
    "colData names(8): n_genes_by_counts log1p_n_genes_by_counts ...\n",
    "  pct_counts_in_top_200_genes pct_counts_in_top_500_genes\n",
    "reducedDimNames(2): X_pca X_umap\n",
    "mainExpName: NULL\n",
    "altExpNames(0):\n",
    "```\n",
    "\n",
    "The same can also be done in reverse:\n",
    "\n",
    "```r\n",
    "adata2 <- zellkonverter::SCE2AnnData(sce, verbose = TRUE)\n",
    "adata2\n",
    "```\n",
    "```\n",
    "ℹ Using the 'X' assay as the X matrix\n",
    "✔ Selected X matrix [27ms]\n",
    "✔ assays$X converted to X matrix [38ms]\n",
    "✔ additional assays converted to layers [31ms]\n",
    "✔ rowData$varm converted to varm [15ms]\n",
    "✔ reducedDims converted to obsm [63ms]\n",
    "✔ metadata converted to uns [23ms]\n",
    "ℹ rowPairs is empty and was skipped\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'X_name', 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability for multimodal data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity of multimodal data presents additional challenges for interoperability. Both the `SingleCellExperiment` (through \"alternative experiments\", which must match in the column dimension (cells)) and `Seurat` (using \"assays\") objects can store multiple modalities but the `AnnData` object is restricted to unimodal data.\n",
    "\n",
    "To address this limitation, the `MuData` object (introduced in the [analysis frameworks and tools chapter]({ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>`) was developed as as an extension of `AnnData` for multimodal datasets. The developers have considered interoperability in their design. While the main platform for MuData is Python, the authors have provided the [MuDataSeurat R package](https://pmbio.github.io/MuDataSeurat/) for reading the on-disk H5MU format as `Seurat` objects and the [MuData R package](https://bioconductor.org/packages/MuData/) for doing the same with Bioconductor `MultiAssayExperiment` objects. This official support is very useful but there are still some inconsistencies due to differences between the objects. The MuData authors also provide a [Julia implementation](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) of `AnnData` and `MuData`.\n",
    "\n",
    "Below is an example of reading and writing a small example `MuData` dataset using the Python and R packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuData object with n_obs × n_vars = 411 × 56\n",
      "  obs:\t'louvain', 'leiden', 'leiden_wnn', 'celltype'\n",
      "  var:\t'gene_ids', 'feature_types', 'highly_variable'\n",
      "  obsm:\t'X_mofa', 'X_mofa_umap', 'X_umap', 'X_wnn_umap'\n",
      "  varm:\t'LFs'\n",
      "  obsp:\t'connectivities', 'distances', 'wnn_connectivities', 'wnn_distances'\n",
      "  2 modalities\n",
      "    prot:\t411 x 29\n",
      "      var:\t'gene_ids', 'feature_types', 'highly_variable'\n",
      "      uns:\t'neighbors', 'pca', 'umap'\n",
      "      obsm:\t'X_pca', 'X_umap'\n",
      "      varm:\t'PCs'\n",
      "      layers:\t'counts'\n",
      "      obsp:\t'connectivities', 'distances'\n",
      "    rna:\t411 x 27\n",
      "      obs:\t'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden', 'celltype'\n",
      "      var:\t'gene_ids', 'feature_types', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
      "      uns:\t'celltype_colors', 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'\n",
      "      obsm:\t'X_pca', 'X_umap'\n",
      "      varm:\t'PCs'\n",
      "      obsp:\t'connectivities', 'distances'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke.zappia/miniconda3/envs/interoperability2/lib/python3.9/site-packages/anndata/_core/anndata.py:1230: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[key] = c\n"
     ]
    }
   ],
   "source": [
    "# Read file\n",
    "mdata = mudata.read_h5mu(\"../../datasets/original.h5mu\")\n",
    "print(mdata)\n",
    "\n",
    "# Write new file\n",
    "python_h5mu_file = os.path.join(temp_dir.name, \"python.h5mu\")\n",
    "mdata.write_h5mu(python_h5mu_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bioconductor\n",
    "\n",
    "Read/write from/to a `MultiAssayExperiment` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A MultiAssayExperiment object of 2 listed\n",
      " experiments with user-defined names and respective classes.\n",
      " Containing an ExperimentList class object of length 2:\n",
      " [1] prot: SingleCellExperiment with 29 rows and 411 columns\n",
      " [2] rna: SingleCellExperiment with 27 rows and 411 columns\n",
      "Functionality:\n",
      " experiments() - obtain the ExperimentList instance\n",
      " colData() - the primary/phenotype DataFrame\n",
      " sampleMap() - the sample coordination DataFrame\n",
      " `$`, `[`, `[[` - extract colData columns, subset, or experiment\n",
      " *Format() - convert into a long or wide DataFrame\n",
      " assays() - convert ExperimentList to a SimpleList of matrices\n",
      " exportClass() - save data to flat files\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mae <- MuData::readH5MU(\"../../datasets/original.h5mu\")\n",
    "print(mae)\n",
    "\n",
    "bioc_h5mu_file <- tempfile(fileext = \".h5mu\")\n",
    "MuData::writeH5MU(mae, bioc_h5mu_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seurat\n",
    "\n",
    "Read/write from/to a `Seurat` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: The legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\n",
      "which was just loaded, will retire in October 2023.\n",
      "Please refer to R-spatial evolution reports for details, especially\n",
      "https://r-spatial.org/r/2023/05/15/evolution4.html.\n",
      "It may be desirable to make the sf package available;\n",
      "package maintainers should consider adding sf to Suggests:.\n",
      "The sp package is now running under evolution status 2\n",
      "     (status 2 uses the sf package in place of rgdal)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Keys should be one or more alphanumeric characters followed by an underscore, setting key from prot to prot_\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'MOFA_1:30'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Keys should be one or more alphanumeric characters followed by an underscore, setting key from MOFA_UMAP_ to MOFAUMAP_\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  All keys should be one or more alphanumeric characters followed by an underscore '_', setting key to MOFAUMAP_\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'MOFAUMAP_1:2'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'UMAP_1:2'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Keys should be one or more alphanumeric characters followed by an underscore, setting key from WNN_UMAP_ to WNNUMAP_\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  All keys should be one or more alphanumeric characters followed by an underscore '_', setting key to WNNUMAP_\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'WNNUMAP_1:2'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'protPCA_1:31'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'protUMAP_1:2'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'rnaPCA_1:50'\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  No columnames present in cell embeddings, setting to 'rnaUMAP_1:2'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "56 features across 411 samples within 2 assays \n",
      "Active assay: prot (29 features, 29 variable features)\n",
      " 1 other assay present: rna\n",
      " 8 dimensional reductions calculated: MOFA, MOFA_UMAP, UMAP, WNN_UMAP, protPCA, protUMAP, rnaPCA, rnaUMAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Added .var['highly_variable'] with highly variable features\n",
      "\n",
      "R[write to console]: Added .var['highly_variable'] with highly variable features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "seurat <- MuDataSeurat::ReadH5MU(\"../../datasets/original.h5mu\")\n",
    "print(seurat)\n",
    "\n",
    "seurat_h5mu_file <- tempfile(fileext = \".h5mu\")\n",
    "MuDataSeurat::WriteH5MU(seurat, seurat_h5mu_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability with other languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we briefly list some resources and tools for the interoperability of single-cell data with languages other than R and Python.\n",
    "\n",
    "### Julia\n",
    "\n",
    "- [Muon.jl](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) provides Julia implementations of `AnnData` and `MuData` objects, as well as IO for the H5AD and H5MU formats\n",
    "- [scVI.jl](https://github.com/maren-ha/scVI.jl) provides a Julia implementation of `AnnData` as well as IO for the H5AD format\n",
    "\n",
    "### JavaScript\n",
    "\n",
    "- [Vitessce](http://vitessce.io/) contains loaders from `AnnData` objects stored using the Zarr format\n",
    "- The [kana family](https://github.com/jkanche/kana) supports reading H5AD files and `SingleCellExperiment` objects saved as RDS files\n",
    "\n",
    "### Rust\n",
    "\n",
    "- [anndata-rs](https://github.com/kaizhang/anndata-rs) provides a Rust implementation of AnnData as well as advanced IO support for the H5AD format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "anndata             0.9.2\n",
       "anndata2ri          1.2\n",
       "mudata              0.2.3\n",
       "numpy               1.24.4\n",
       "rpy2                3.5.11\n",
       "scanpy              1.9.3\n",
       "scipy               1.9.3\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "CoreFoundation              NA\n",
       "Foundation                  NA\n",
       "PIL                         10.0.0\n",
       "PyObjCTools                 NA\n",
       "anyio                       NA\n",
       "appnope                     0.1.3\n",
       "argcomplete                 NA\n",
       "arrow                       1.2.3\n",
       "asttokens                   NA\n",
       "attr                        23.1.0\n",
       "attrs                       23.1.0\n",
       "babel                       2.12.1\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "brotli                      1.0.9\n",
       "certifi                     2023.07.22\n",
       "cffi                        1.15.1\n",
       "charset_normalizer          3.2.0\n",
       "colorama                    0.4.6\n",
       "comm                        0.1.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.6.8\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "executing                   1.2.0\n",
       "fastjsonschema              NA\n",
       "fqdn                        NA\n",
       "h5py                        3.9.0\n",
       "hypergeom_ufunc             NA\n",
       "idna                        3.4\n",
       "importlib_metadata          NA\n",
       "importlib_resources         NA\n",
       "ipykernel                   6.25.0\n",
       "ipython_genutils            0.2.0\n",
       "ipywidgets                  8.1.0\n",
       "isoduration                 NA\n",
       "jedi                        0.19.0\n",
       "jinja2                      3.1.2\n",
       "joblib                      1.3.0\n",
       "json5                       NA\n",
       "jsonpointer                 2.0\n",
       "jsonschema                  4.18.6\n",
       "jsonschema_specifications   NA\n",
       "jupyter_events              0.7.0\n",
       "jupyter_server              2.7.0\n",
       "jupyterlab_server           2.24.0\n",
       "kiwisolver                  1.4.4\n",
       "llvmlite                    0.40.1\n",
       "markupsafe                  2.1.3\n",
       "matplotlib                  3.7.2\n",
       "mpl_toolkits                NA\n",
       "natsort                     8.4.0\n",
       "nbformat                    5.9.2\n",
       "nbinom_ufunc                NA\n",
       "ncf_ufunc                   NA\n",
       "numba                       0.57.1\n",
       "objc                        9.2\n",
       "overrides                   NA\n",
       "packaging                   23.1\n",
       "pandas                      2.0.3\n",
       "parso                       0.8.3\n",
       "pexpect                     4.8.0\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                3.10.0\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.39\n",
       "psutil                      5.9.5\n",
       "ptyprocess                  0.7.0\n",
       "pure_eval                   0.2.2\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.9.5\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.15.1\n",
       "pyparsing                   3.0.9\n",
       "pythonjsonlogger            NA\n",
       "pytz                        2023.3\n",
       "referencing                 NA\n",
       "requests                    2.31.0\n",
       "rfc3339_validator           0.1.4\n",
       "rfc3986_validator           0.1.1\n",
       "rpds                        NA\n",
       "send2trash                  NA\n",
       "six                         1.16.0\n",
       "sklearn                     1.3.0\n",
       "sniffio                     1.3.0\n",
       "socks                       1.7.1\n",
       "stack_data                  0.6.2\n",
       "threadpoolctl               3.2.0\n",
       "tornado                     6.3.2\n",
       "traitlets                   5.9.0\n",
       "typing_extensions           NA\n",
       "tzlocal                     NA\n",
       "uri_template                NA\n",
       "urllib3                     2.0.4\n",
       "wcwidth                     0.2.6\n",
       "webcolors                   1.13\n",
       "websocket                   1.6.1\n",
       "yaml                        6.0\n",
       "zipp                        NA\n",
       "zmq                         25.1.0\n",
       "zoneinfo                    NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.14.0\n",
       "jupyter_client      8.3.0\n",
       "jupyter_core        5.3.1\n",
       "jupyterlab          3.6.3\n",
       "notebook            6.5.4\n",
       "-----\n",
       "Python 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:42:20) [Clang 14.0.6 ]\n",
       "macOS-13.4.1-x86_64-i386-64bit\n",
       "-----\n",
       "Session information updated at 2023-11-15 15:48\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "─ Session info ───────────────────────────────────────────────────────────────\n",
      " setting  value\n",
      " version  R version 4.2.3 (2023-03-15)\n",
      " os       macOS Ventura 13.4.1\n",
      " system   x86_64, darwin13.4.0\n",
      " ui       unknown\n",
      " language (EN)\n",
      " collate  C\n",
      " ctype    UTF-8\n",
      " tz       Europe/Berlin\n",
      " date     2023-11-15\n",
      " pandoc   2.19.2 @ /Users/luke.zappia/miniconda3/envs/interoperability2/bin/pandoc\n",
      "\n",
      "─ Packages ───────────────────────────────────────────────────────────────────\n",
      " package              * version    date (UTC) lib source\n",
      " abind                  1.4-5      2016-07-21 [1] CRAN (R 4.2.3)\n",
      " Biobase                2.58.0     2022-11-01 [1] Bioconductor\n",
      " BiocGenerics           0.44.0     2022-11-01 [1] Bioconductor\n",
      " bit                    4.0.5      2022-11-15 [1] CRAN (R 4.2.3)\n",
      " bit64                  4.0.5      2020-08-30 [1] CRAN (R 4.2.3)\n",
      " bitops                 1.0-7      2021-04-24 [1] CRAN (R 4.2.3)\n",
      " cli                    3.6.1      2023-03-23 [1] CRAN (R 4.2.3)\n",
      " cluster                2.1.4      2022-08-22 [1] CRAN (R 4.2.3)\n",
      " codetools              0.2-19     2023-02-01 [1] CRAN (R 4.2.3)\n",
      " colorspace             2.1-0      2023-01-23 [1] CRAN (R 4.2.3)\n",
      " cowplot                1.1.1      2020-12-30 [1] CRAN (R 4.2.3)\n",
      " data.table             1.14.8     2023-02-17 [1] CRAN (R 4.2.3)\n",
      " DelayedArray           0.24.0     2022-11-01 [1] Bioconductor\n",
      " deldir                 1.0-9      2023-05-17 [1] CRAN (R 4.2.3)\n",
      " digest                 0.6.33     2023-07-07 [1] CRAN (R 4.2.3)\n",
      " dplyr                  1.1.2      2023-04-20 [1] CRAN (R 4.2.3)\n",
      " ellipsis               0.3.2      2021-04-29 [1] CRAN (R 4.2.3)\n",
      " fansi                  1.0.4      2023-01-22 [1] CRAN (R 4.2.3)\n",
      " fastmap                1.1.1      2023-02-24 [1] CRAN (R 4.2.3)\n",
      " fitdistrplus           1.1-11     2023-04-25 [1] CRAN (R 4.2.3)\n",
      " future                 1.33.0     2023-07-01 [1] CRAN (R 4.2.3)\n",
      " future.apply           1.11.0     2023-05-21 [1] CRAN (R 4.2.3)\n",
      " generics               0.1.3      2022-07-05 [1] CRAN (R 4.2.3)\n",
      " GenomeInfoDb           1.34.9     2023-02-02 [1] Bioconductor\n",
      " GenomeInfoDbData       1.2.9      2023-11-10 [1] Bioconductor\n",
      " GenomicRanges          1.50.0     2022-11-01 [1] Bioconductor\n",
      " ggplot2                3.4.2      2023-04-03 [1] CRAN (R 4.2.3)\n",
      " ggrepel                0.9.3      2023-02-03 [1] CRAN (R 4.2.3)\n",
      " ggridges               0.5.4      2022-09-26 [1] CRAN (R 4.2.3)\n",
      " globals                0.16.2     2022-11-21 [1] CRAN (R 4.2.3)\n",
      " glue                   1.6.2      2022-02-24 [1] CRAN (R 4.2.3)\n",
      " goftest                1.2-3      2021-10-07 [1] CRAN (R 4.2.3)\n",
      " gridExtra              2.3        2017-09-09 [1] CRAN (R 4.2.3)\n",
      " gtable                 0.3.3      2023-03-21 [1] CRAN (R 4.2.3)\n",
      " hdf5r                  1.3.8      2023-01-21 [1] CRAN (R 4.2.3)\n",
      " htmltools              0.5.5      2023-03-23 [1] CRAN (R 4.2.3)\n",
      " htmlwidgets            1.6.2      2023-03-17 [1] CRAN (R 4.2.3)\n",
      " httpuv                 1.6.11     2023-05-11 [1] CRAN (R 4.2.3)\n",
      " httr                   1.4.6      2023-05-08 [1] CRAN (R 4.2.3)\n",
      " ica                    1.0-3      2022-07-08 [1] CRAN (R 4.2.3)\n",
      " igraph                 1.5.0.1    2023-07-23 [1] CRAN (R 4.2.3)\n",
      " IRanges                2.32.0     2022-11-01 [1] Bioconductor\n",
      " irlba                  2.3.5.1    2022-10-03 [1] CRAN (R 4.2.3)\n",
      " jsonlite               1.8.7      2023-06-29 [1] CRAN (R 4.2.3)\n",
      " KernSmooth             2.23-22    2023-07-10 [1] CRAN (R 4.2.3)\n",
      " later                  1.3.1      2023-05-02 [1] CRAN (R 4.2.3)\n",
      " lattice                0.21-8     2023-04-05 [1] CRAN (R 4.2.3)\n",
      " lazyeval               0.2.2      2019-03-15 [1] CRAN (R 4.2.3)\n",
      " leiden                 0.4.3      2022-09-10 [1] CRAN (R 4.2.3)\n",
      " lifecycle              1.0.3      2022-10-07 [1] CRAN (R 4.2.3)\n",
      " listenv                0.9.0      2022-12-16 [1] CRAN (R 4.2.3)\n",
      " lmtest                 0.9-40     2022-03-21 [1] CRAN (R 4.2.3)\n",
      " magrittr               2.0.3      2022-03-30 [1] CRAN (R 4.2.3)\n",
      " MASS                   7.3-60     2023-05-04 [1] CRAN (R 4.2.3)\n",
      " Matrix                 1.6-0      2023-07-08 [1] CRAN (R 4.2.3)\n",
      " MatrixGenerics         1.10.0     2022-11-01 [1] Bioconductor\n",
      " matrixStats            1.0.0      2023-06-02 [1] CRAN (R 4.2.3)\n",
      " mime                   0.12       2021-09-28 [1] CRAN (R 4.2.3)\n",
      " miniUI                 0.1.1.1    2018-05-18 [1] CRAN (R 4.2.3)\n",
      " MuData                 1.2.0      2022-11-01 [1] Bioconductor\n",
      " MuDataSeurat           0.0.0.9000 2023-11-15 [1] Github (PMBio/MuDataSeurat@e34e908)\n",
      " MultiAssayExperiment   1.24.0     2022-11-01 [1] Bioconductor\n",
      " munsell                0.5.0      2018-06-12 [1] CRAN (R 4.2.3)\n",
      " nlme                   3.1-162    2023-01-31 [1] CRAN (R 4.2.3)\n",
      " parallelly             1.36.0     2023-05-26 [1] CRAN (R 4.2.3)\n",
      " patchwork              1.1.2      2022-08-19 [1] CRAN (R 4.2.3)\n",
      " pbapply                1.7-2      2023-06-27 [1] CRAN (R 4.2.3)\n",
      " pillar                 1.9.0      2023-03-22 [1] CRAN (R 4.2.3)\n",
      " pkgconfig              2.0.3      2019-09-22 [1] CRAN (R 4.2.3)\n",
      " plotly                 4.10.2     2023-06-03 [1] CRAN (R 4.2.3)\n",
      " plyr                   1.8.8      2022-11-11 [1] CRAN (R 4.2.3)\n",
      " png                    0.1-8      2022-11-29 [1] CRAN (R 4.2.3)\n",
      " polyclip               1.10-4     2022-10-20 [1] CRAN (R 4.2.3)\n",
      " progressr              0.13.0     2023-01-10 [1] CRAN (R 4.2.3)\n",
      " promises               1.2.0.1    2021-02-11 [1] CRAN (R 4.2.3)\n",
      " purrr                  1.0.1      2023-01-10 [1] CRAN (R 4.2.3)\n",
      " R6                     2.5.1      2021-08-19 [1] CRAN (R 4.2.3)\n",
      " RANN                   2.6.1      2019-01-08 [1] CRAN (R 4.2.3)\n",
      " RColorBrewer           1.1-3      2022-04-03 [1] CRAN (R 4.2.3)\n",
      " Rcpp                   1.0.11     2023-07-06 [1] CRAN (R 4.2.3)\n",
      " RcppAnnoy              0.0.21     2023-07-02 [1] CRAN (R 4.2.3)\n",
      " RCurl                  1.98-1.12  2023-03-27 [1] CRAN (R 4.2.3)\n",
      " reshape2               1.4.4      2020-04-09 [1] CRAN (R 4.2.3)\n",
      " reticulate             1.30       2023-06-09 [1] CRAN (R 4.2.3)\n",
      " rhdf5                  2.42.0     2022-11-01 [1] Bioconductor\n",
      " rhdf5filters           1.10.0     2022-11-01 [1] Bioconductor\n",
      " Rhdf5lib               1.20.0     2022-11-01 [1] Bioconductor\n",
      " rlang                  1.1.1      2023-04-28 [1] CRAN (R 4.2.3)\n",
      " ROCR                   1.0-11     2020-05-02 [1] CRAN (R 4.2.3)\n",
      " Rtsne                  0.16       2022-04-17 [1] CRAN (R 4.2.3)\n",
      " S4Vectors              0.36.0     2022-11-01 [1] Bioconductor\n",
      " scales                 1.2.1      2022-08-20 [1] CRAN (R 4.2.3)\n",
      " scattermore            1.2        2023-06-12 [1] CRAN (R 4.2.3)\n",
      " sctransform            0.3.5      2022-09-21 [1] CRAN (R 4.2.3)\n",
      " sessioninfo            1.2.2      2021-12-06 [1] CRAN (R 4.2.3)\n",
      " Seurat                 4.3.0.1    2023-06-22 [1] CRAN (R 4.2.3)\n",
      " SeuratObject           4.1.3      2022-11-07 [1] CRAN (R 4.2.3)\n",
      " shiny                  1.7.4.1    2023-07-06 [1] CRAN (R 4.2.3)\n",
      " SingleCellExperiment   1.20.0     2022-11-01 [1] Bioconductor\n",
      " sp                     2.0-0      2023-06-22 [1] CRAN (R 4.2.3)\n",
      " spatstat.data          3.0-1      2023-03-12 [1] CRAN (R 4.2.3)\n",
      " spatstat.explore       3.2-1      2023-05-13 [1] CRAN (R 4.2.3)\n",
      " spatstat.geom          3.2-4      2023-07-20 [1] CRAN (R 4.2.3)\n",
      " spatstat.random        3.1-5      2023-05-11 [1] CRAN (R 4.2.3)\n",
      " spatstat.sparse        3.0-2      2023-06-25 [1] CRAN (R 4.2.3)\n",
      " spatstat.utils         3.0-3      2023-05-09 [1] CRAN (R 4.2.3)\n",
      " stringi                1.7.12     2023-01-11 [1] CRAN (R 4.2.3)\n",
      " stringr                1.5.0      2022-12-02 [1] CRAN (R 4.2.3)\n",
      " SummarizedExperiment   1.28.0     2022-11-01 [1] Bioconductor\n",
      " survival               3.5-5      2023-03-12 [1] CRAN (R 4.2.3)\n",
      " tensor                 1.5        2012-05-05 [1] CRAN (R 4.2.3)\n",
      " tibble                 3.2.1      2023-03-20 [1] CRAN (R 4.2.3)\n",
      " tidyr                  1.3.0      2023-01-24 [1] CRAN (R 4.2.3)\n",
      " tidyselect             1.2.0      2022-10-10 [1] CRAN (R 4.2.3)\n",
      " utf8                   1.2.3      2023-01-31 [1] CRAN (R 4.2.3)\n",
      " uwot                   0.1.16     2023-06-29 [1] CRAN (R 4.2.3)\n",
      " vctrs                  0.6.3      2023-06-14 [1] CRAN (R 4.2.3)\n",
      " viridisLite            0.4.2      2023-05-02 [1] CRAN (R 4.2.3)\n",
      " xtable                 1.8-4      2019-04-21 [1] CRAN (R 4.2.3)\n",
      " XVector                0.38.0     2022-11-01 [1] Bioconductor\n",
      " zlibbioc               1.44.0     2022-11-01 [1] Bioconductor\n",
      " zoo                    1.8-12     2023-04-13 [1] CRAN (R 4.2.3)\n",
      "\n",
      " [1] /Users/luke.zappia/miniconda3/envs/interoperability2/lib/R/library\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sessioninfo::session_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":labelprefix: int\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "We gratefully acknowledge the contributions of:\n",
    "\n",
    "### Authors\n",
    "\n",
    "* Luke Zappia\n",
    "\n",
    "### Reviewers\n",
    "\n",
    "* Lukas Heumos\n",
    "* Isaac Virshup\n",
    "* Anastasia Litinetskaya\n",
    "* Ludwig Geistlinger\n",
    "* Peter Hickey"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d105ab5f2493203880d03226e61049059fafcfb5de79a5a432ed345ee74ab31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
