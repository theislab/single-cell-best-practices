{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{dropdown} <i class=\"fas fa-brain\"></i>&nbsp;&nbsp;&nbsp;Key takeaways\n",
    "\n",
    ":::{card}\n",
    ":link: introduction-interoperability-key-takeaway-1\n",
    ":link-type: ref\n",
    "Interoperabilty between languages allows analysts to take advantage of the strengths of different ecosystems.\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    ":link: introduction-interoperability-key-takeaway-2\n",
    ":link-type: ref\n",
    "On-disk interoperability uses standard file formats to transfer data and is typically more reliable.\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    ":link: introduction-interoperability-key-takeaway-3\n",
    ":link-type: ref\n",
    "In-memory interoperabilty transfers data directly between parallel sessions and is convenient for interactive analysis.\n",
    ":::\n",
    "\n",
    ":::{card}\n",
    ":link: introduction-interoperability-key-takeaway-4\n",
    ":link-type: ref\n",
    "While interoperability is currently possible developers continue to improve the experience.\n",
    ":::\n",
    "\n",
    "```\n",
    "\n",
    "<!-- START ENV-SETUP -->\n",
    "<!-- END ENV-SETUP -->\n",
    "<!-- START LAMIN-SETUP -->\n",
    "<!-- END LAMIN-SETUP -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(introduction-interoperability-key-takeaway-1)=\n",
    "(introduction-interoperability-key-takeaway-4)=\n",
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have discussed in the {ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>`, there are three main ecosystems for single-cell analysis: the [Bioconductor](https://bioconductor.org/) and [Seurat](https://satijalab.org/seurat/index.html) ecosystems in R and the Python-based [scverse](https://scverse.org/) ecosystem.\n",
    "A common question from new analysts is which ecosystem they should focus on learning and using.\n",
    "While it makes sense to focus on one to start with, and a successful standard analysis can be performed in any ecosystem, we promote the idea that competent analysts should be familiar with all three ecosystems and comfortable moving between them.\n",
    "This approach allows analysts to use the best-performing tools and methods regardless of their implementation.\n",
    "When analysts are not comfortable moving between ecosystems, they often tend to use packages that are easy to access, even when they have been shown to have shortcomings compared to packages in another ecosystem.\n",
    "The ability of analysts to move between ecosystems allows developers to take advantage of the different strengths of programming languages.\n",
    "For example, R has strong built-in support for complex statistical modeling, while most deep-learning libraries focus on Python.\n",
    "By supporting common on-disk data formats and in-memory data structures, developers can be confident that analysts can access their packages and use the platform most appropriate for their method.\n",
    "Another motivation for being comfortable with multiple ecosystems is the accessibility and availability of data, results, and documentation.\n",
    "Data or results are often only made available in one format, and analysts will need to be familiar with that format to access it.\n",
    "A basic understanding of other ecosystems is also necessary to understand package documentation and tutorials when deciding which methods to use.\n",
    "\n",
    "While we encourage analysts to be comfortable with all the major ecosystems, moving between them is only possible when they are interoperable.\n",
    "Thankfully, much work has been done in this area, and using standard packages is now relatively simple in most cases.\n",
    "In this chapter, we discuss the various ways data can be moved between ecosystems via disk or memory, their differences, and their advantages.\n",
    "We focus on single-modality data and moving between R and Python, as these are the most common cases, but we also touch on multimodal data and other languages.\n",
    "\n",
    "We first import all required Python packages before going through the chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m→\u001b[0m connected lamindb: theislab/sc-best-practices\n",
      "\u001b[92m→\u001b[0m created Transform('QaILJZMpZyJ40000'), started new Run('1YEGroVZ...') at 2025-03-26 12:58:46 UTC\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import anndata2ri\n",
    "import lamindb as ln\n",
    "import rpy2.robjects\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "assert ln.setup.settings.instance.slug == \"theislab/sc-best-practices\"\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomenclature\n",
    "\n",
    "Because talking about different languages can get confusing we try to use the following conventions:\n",
    "\n",
    "- **{package}** - An R package\n",
    "- `package::function()` - A function in an R package\n",
    "- **package** - A Python package\n",
    "- `package.function()` - A function in a Python package\n",
    "- **Emphasised** - Some other important concept\n",
    "- `code` - Other parts of code including objects, variables etc. This is also used for files or directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk-based interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach to moving between languages is via disk-based interoperability.\n",
    "This involves writing a file to disk in one language and then reading that file into a second language.\n",
    "In many cases, this approach is simpler, more reliable and scalable than in-memory interoperability (which we discuss below).\n",
    "Still, it comes at the cost of greater storage requirements and reduced interactivity.\n",
    "Disk-based interoperability tends to work particularly well when there are established processes for each stage of analysis and you want to pass objects from one to the next (especially as part of a pipeline developed using a workflow manager such as [Nextflow](https://www.nextflow.io/index.html) or [snakemake](https://snakemake.readthedocs.io/en/stable/)).\n",
    "However, disk-based interoperability is less convenient for interactive steps such as data exploration or experimenting with methods, as you need to write a new file whenever you want to move between languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(introduction-interoperability-key-takeaway-2)=\n",
    "### Simple formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing file formats specifically developed for single-cell data we want to briefly mention that common simple text file formats (such as CSV, TSV, JSON etc.) can often be the answer to transferring data between languages.\n",
    "They work well in cases where some analysis has been performed, and what you want to transfer is a subset of the information about an experiment.\n",
    "For example, you may want to transfer only the cell metadata but do not require the feature metadata, expression matrices etc.\n",
    "The advantage of using simple text formats is that they are well supported by almost any language and do not require single-cell specific packages.\n",
    "However, they can quickly become impractical as what you want to transfer becomes more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5-based formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hierarchical Data Format version 5](https://www.hdfgroup.org/solutions/hdf5/) (HDF5) is the most common open-source file format for storing single-cell data.\n",
    "It is designed for large, complex, and heterogeneous datasets, using a directory-like structure similar to a computer's file system.\n",
    "This allows multiple types of data to be stored within a single file in an organized hierarchy. While HDF5 is highly flexible, interacting with it requires knowledge of how data is structured within the file.\n",
    "To standardize this process, specific guidelines have been developed for storing single-cell data in HDF5 files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H5AD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H5AD format is the HDF5 disk representation of the `AnnData` object used by scverse packages and is commonly used to share single-cell datasets.\n",
    "As it is part of the scverse ecosystem, reading and writing these files from Python is well-supported and is part of the core functionality of the [**anndata** package](https://anndata.readthedocs.io/en/latest/index.html) (read more about the format [here](https://anndata.readthedocs.io/en/latest/fileformat-prose.html)).\n",
    "\n",
    "To demonstrate interoperability, we will load a small, randomly generated dataset that has gone through some of the steps of a standard analysis workflow to populate the various slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 100 × 2000\n",
       "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
       "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af = ln.Artifact.get(key=\"introduction/interoperability_adata.h5ad\", is_latest=True)\n",
    "adata = af.load()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write this mock object to disk as a H5AD file to demonstrate how those files can be read from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "h5ad_file = str(Path(temp_dir.name) / \"example.h5ad\")\n",
    "\n",
    "adata.write_h5ad(h5ad_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several R packages support reading and writing H5AD files.\n",
    "However, they typically wrap the Python **anndata** package for file handling, using an in-memory conversion step to bridge data between R and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with Bioconductor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Bioconductor **{zellkonverter}** package](https://bioconductor.org/packages/zellkonverter/) simplifies H5AD file handling by using the [**{basilisk}** package](https://bioconductor.org/packages/basilisk/) to manage a compatible Python environment.\n",
    "In other words, it enables Bioconductor users to read and write H5AD files seamlessly, without needing any Python knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, because of the way this book is made, we are unable to run the code directly here. Instead, we will show the code and what the output looks like when run in an R session:\n",
    "\n",
    "```r\n",
    "sce <- zellkonverter::readH5AD(h5ad_file, verbose = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "ℹ Using the Python reader\n",
    "ℹ Using anndata version 0.8.0\n",
    "✔ Read /.../luke.zappia/Downloads/example.h5ad [113ms]\n",
    "✔ uns$hvg$flavor converted [17ms]\n",
    "✔ uns$hvg converted [50ms]\n",
    "✔ uns$log1p converted [25ms]\n",
    "✔ uns$neighbors converted [18ms]\n",
    "✔ uns$pca$params$use_highly_variable converted [16ms]\n",
    "✔ uns$pca$params$zero_center converted [16ms]\n",
    "✔ uns$pca$params converted [80ms]\n",
    "✔ uns$pca$variance converted [17ms]\n",
    "✔ uns$pca$variance_ratio converted [16ms]\n",
    "✔ uns$pca converted [184ms]\n",
    "✔ uns$umap$params$a converted [16ms]\n",
    "✔ uns$umap$params$b converted [16ms]\n",
    "✔ uns$umap$params converted [80ms]\n",
    "✔ uns$umap converted [112ms]\n",
    "✔ uns converted [490ms]\n",
    "✔ Converting uns to metadata ... done\n",
    "✔ X matrix converted to assay [29ms]\n",
    "✔ layers$counts converted [27ms]\n",
    "✔ Converting layers to assays ... done\n",
    "✔ var converted to rowData [25ms]\n",
    "✔ obs converted to colData [24ms]\n",
    "✔ varm$PCs converted [18ms]\n",
    "✔ varm converted [47ms]\n",
    "✔ Converting varm to rowData$varm ... done\n",
    "✔ obsm$X_pca converted [15ms]\n",
    "✔ obsm$X_umap converted [16ms]\n",
    "✔ obsm converted [80ms]\n",
    "✔ Converting obsm to reducedDims ... done\n",
    "ℹ varp is empty and was skipped\n",
    "✔ obsp$connectivities converted [22ms]\n",
    "✔ obsp$distances converted [23ms]\n",
    "✔ obsp converted [92ms]\n",
    "✔ Converting obsp to colPairs ... done\n",
    "✔ SingleCellExperiment constructed [164ms]\n",
    "ℹ Skipping conversion of raw\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "```\n",
    "\n",
    "Because we have turned on the verbose output you can see how **{zellkonverter}** reads the file using Python and converts each part of the `AnnData` object to a Bioconductor `SingleCellExperiment` object. We can see what the result looks like:\n",
    "\n",
    "```r\n",
    "sce\n",
    "```\n",
    "\n",
    "```\n",
    "class: SingleCellExperiment\n",
    "dim: 2000 100\n",
    "metadata(5): hvg log1p neighbors pca umap\n",
    "assays(2): X counts\n",
    "rownames(2000): Gene_0 Gene_1 ... Gene_1998 Gene_1999\n",
    "rowData names(11): n_cells_by_counts mean_counts ... dispersions_norm\n",
    "  varm\n",
    "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
    "colData names(8): n_genes_by_counts log1p_n_genes_by_counts ...\n",
    "  pct_counts_in_top_200_genes pct_counts_in_top_500_genes\n",
    "reducedDimNames(2): X_pca X_umap\n",
    "mainExpName: NULL\n",
    "altExpNames(0):\n",
    "```\n",
    "\n",
    "This object can then be used as normal by any Bioconductor package. If we want to write a new H5AD file we can use the `writeH5AD()` function:\n",
    "\n",
    "```r\n",
    "zellkonverter_h5ad_file <- tempfile(fileext = \".h5ad\")\n",
    "zellkonverter::writeH5AD(sce, zellkonverter_h5ad_file, verbose = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "ℹ Using anndata version 0.8.0\n",
    "ℹ Using the 'X' assay as the X matrix\n",
    "✔ Selected X matrix [29ms]\n",
    "✔ assays$X converted to X matrix [50ms]\n",
    "✔ additional assays converted to layers [30ms]\n",
    "✔ rowData$varm converted to varm [28ms]\n",
    "✔ reducedDims converted to obsm [68ms]\n",
    "✔ metadata converted to uns [24ms]\n",
    "ℹ rowPairs is empty and was skipped\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "✔ Wrote '/.../.../rj/.../T/.../file102cfa97cc51.h5ad ' [133ms]\n",
    "```\n",
    "\n",
    "We can then read this file in Python:\n",
    "\n",
    "```python\n",
    "scanpy.read_h5ad(zellkonverter_h5ad_file)\n",
    "```\n",
    "\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'X_name', 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re running a **{zellkonverter}** function for the first time, it will create a special Conda environment, which may take some time.\n",
    "Once created, this environment is reused for subsequent function calls.\n",
    "**{zellkonverter}** also offers options such as selectively reading or writing parts of an object.\n",
    "For more details, refer to the package documentation.\n",
    "\n",
    "Similar functionality for writing a`SingleCellExperiment` object to an H5AD file is available in the [**{sceasy}** package](https://github.com/cellgeni/sceasy).\n",
    "While these packages are effective, wrapping Python introduces some overhead, which future native R H5AD writers/readers may help optimize."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with **{Seurat}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `h5ad_file` is a `Path` object, the way we use R in this notebook expects a string, so we convert it into a `string` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ad_file = str(h5ad_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between a `Seurat` object and an H5AD file is a two-step process [as suggested by this tutorial](https://mojaveazure.github.io/seurat-disk/articles/convert-anndata.html).\n",
    "First, the H5AD file is converted to an H5Seurat file—a custom HDF5 format for `Seurat` objects—using the [**{SeuratDisk}** package](https://mojaveazure.github.io/seurat-disk/).\n",
    "The H5Seurat file is then read as a `Seurat` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Converting H5AD to H5Seurat...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Registered S3 method overwritten by 'SeuratDisk':\n",
      "  method            from  \n",
      "  as.sparse.H5Group Seurat\n",
      "\n",
      "R[write to console]: 경고:\n",
      "R[write to console]:  Unknown file type: h5ad\n",
      "\n",
      "R[write to console]: 경고:\n",
      "R[write to console]:  'assay' not set, setting to 'RNA'\n",
      "\n",
      "R[write to console]: Creating h5Seurat file for version 3.1.5.9900\n",
      "\n",
      "R[write to console]: Adding X as data\n",
      "\n",
      "R[write to console]: Adding X as counts\n",
      "\n",
      "R[write to console]: Adding meta.features from var\n",
      "\n",
      "R[write to console]: Adding X_pca as cell embeddings for pca\n",
      "\n",
      "R[write to console]: Adding X_umap as cell embeddings for umap\n",
      "\n",
      "R[write to console]: Adding PCs as feature loadings fpr pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for pca\n",
      "\n",
      "R[write to console]: Adding standard deviations for pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for umap\n",
      "\n",
      "R[write to console]: Adding hvg to miscellaneous data\n",
      "\n",
      "R[write to console]: Adding log1p to miscellaneous data\n",
      "\n",
      "R[write to console]: Adding layer counts as data in assay counts\n",
      "\n",
      "R[write to console]: Adding layer counts as counts in assay counts\n",
      "\n",
      "R[write to console]: Reading H5Seurat...\n",
      "\n",
      "R[write to console]: Validating h5Seurat file\n",
      "\n",
      "R[write to console]: 경고:\n",
      "R[write to console]:  Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
      "\n",
      "R[write to console]: Initializing RNA with data\n",
      "\n",
      "R[write to console]: Adding counts for RNA\n",
      "\n",
      "R[write to console]: Adding feature-level metadata for RNA\n",
      "\n",
      "R[write to console]: Adding reduction pca\n",
      "\n",
      "R[write to console]: Adding cell embeddings for pca\n",
      "\n",
      "R[write to console]: Adding feature loadings for pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for pca\n",
      "\n",
      "R[write to console]: Adding reduction umap\n",
      "\n",
      "R[write to console]: Adding cell embeddings for umap\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for umap\n",
      "\n",
      "R[write to console]: Adding command information\n",
      "\n",
      "R[write to console]: Adding cell-level metadata\n",
      "\n",
      "R[write to console]: Read Seurat object:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "2000 features across 100 samples within 1 assay \n",
      "Active assay: RNA (2000 features, 0 variable features)\n",
      " 2 layers present: counts, data\n",
      " 2 dimensional reductions calculated: pca, umap\n"
     ]
    }
   ],
   "source": [
    "%%R -i h5ad_file\n",
    "\n",
    "message(\"Converting H5AD to H5Seurat...\")\n",
    "SeuratDisk::Convert(h5ad_file, dest = \"h5seurat\", overwrite = TRUE)\n",
    "message(\"Reading H5Seurat...\")\n",
    "h5seurat_file <- gsub(\".h5ad\", \".h5seurat\", h5ad_file)\n",
    "seurat <- SeuratDisk::LoadH5Seurat(h5seurat_file, assays = \"RNA\")\n",
    "message(\"Read Seurat object:\")\n",
    "seurat\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that converting a `Seurat` object is more complex compared to `AnnData` or `SingleCellExperiment` due to structural differences.\n",
    "For more details, refer to the [conversion function documentation](https://mojaveazure.github.io/seurat-disk/reference/Convert.html).\n",
    "\n",
    "The **{sceasy}** package allows direct reading of H5AD files into `Seurat` or `SingleCellExperiment` objects.\n",
    "Unlike **{zellkonverter}**, which relies on a dedicated Python environment, **{sceasy}** wraps Python functions without requiring a special setup.\n",
    "However, this means you must manually configure the environment, ensure R can locate it, and install the necessary packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "sceasy_seurat <- sceasy::convertFormat(h5ad_file, from=\"anndata\", to=\"seurat\")\n",
    "sceasy_seurat\n",
    "```\n",
    "```\n",
    "Warning: Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
    "X -> counts\n",
    "An object of class Seurat\n",
    "2000 features across 100 samples within 1 assay\n",
    "Active assay: RNA (2000 features, 0 variable features)\n",
    " 2 dimensional reductions calculated: pca, umap\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with **{anndata}**\n",
    "\n",
    "The R [**{anndata}** package](https://anndata.dynverse.org/index.html) can also be used to read H5AD files.\n",
    "However, unlike the packages above, it does not convert to a native R object.\n",
    "Instead it provides an R interface to the Python object.\n",
    "This is useful for accessing the data but few analysis packages will accept this as input, so further in-memory conversion is usually required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Loom file format](http://loompy.org/) is an older HDF5-based specification for omics data.\n",
    "While similar in structure to `AnnData and SingleCellExperiment`, it is not tied to a specific analysis ecosystem like H5AD.\n",
    "Loom format support is available in both [R](https://github.com/mojaveazure/loomR) and [Python](https://pypi.org/project/loompy/), as well as through the [Bioconductor package](https://bioconductor.org/packages/LoomExperiment/) for writing Loom files.\n",
    "However, it is often more convenient to use the higher-level interfaces provided by core ecosystem packages.\n",
    "Beyond dataset sharing, Loom files are commonly encountered when analyzing spliced and unspliced reads using [velocyto](http://velocyto.org/) for {ref}`RNA velocity analysis <trajectories:rna-velocity>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another file format you may see used to share single-cell datasets is the RDS format.\n",
    "This is a binary format used to serialize arbitrary `R` objects (similar to Python Pickle files).\n",
    "As `SingleCellExperiment` and `Seurat` objects did not always have matching on-disk representations, RDS files are sometimes used to share the results from R analyses.\n",
    "While this is ok within an analysis project, we discourage its use for sharing data publicly or with collaborators due to the lack of interoperability with other ecosystems.\n",
    "Instead, we recommend using one of the HDF5 formats mentioned above that can be read from multiple languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New on-disk formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While HDF5-based formats are currently the standard for on-disk representations of single-cell data, other newer technologies such as [Zarr](https://zarr.dev/) and [TileDB](https://tiledb.com/) have some advantages, particularly for very large datasets and other modalities.\n",
    "We expect specifications to be developed for these formats in the future, which may be adopted by the community (**anndata** already provides support for Zarr files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Key point\n",
    "- `SingleCellExperiment`: Bioconductor standard for single-cell data in R. Conversion between `Anndata` and `SingleCellExperiment` can be done by `zellkonverter`\n",
    "- `Seurat`: Single-cell analysis framework in R. It can read/write `AnnData` via `SeuratDisk` or convert via `sceasy`\n",
    "- `AnnData`: Standard format for single-cell data in Python\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-memory interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach to interoperability is to work on in-memory representations of an object.\n",
    "This approach involves active sessions from two programming languages running at the same time and either accessing the same object from both or converting between them as needed.\n",
    "Usually, one language acts as the main environment, and there is an interface to the other language.\n",
    "This can be very useful for interactive analysis as it allows an analyst to work in two languages simultaneously.\n",
    "It is also often used when creating documents that use multiple languages (such as this book).\n",
    "However, in-memory interoperability has some drawbacks.\n",
    "Analysts must be familiar with setting up and using both environments, complex objects may not be fully supported across languages, and data duplication increases memory overhead, making it less suitable for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interoperability between R ecosystems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at in-memory interoperability between R and Python, let’s consider the simpler case of converting between the two R ecosystems.\n",
    "The **{Seurat}** package provides functions for performing this conversion [as described in this vignette](https://satijalab.org/seurat/articles/conversion_vignette.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: SingleCellExperiment \n",
      "dim: 2000 100 \n",
      "metadata(0):\n",
      "assays(2): counts logcounts\n",
      "rownames(2000): Gene-0 Gene-1 ... Gene-1998 Gene-1999\n",
      "rowData names(0):\n",
      "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
      "colData names(9): n_genes_by_counts log1p_n_genes_by_counts ...\n",
      "  pct_counts_in_top_500_genes ident\n",
      "reducedDimNames(2): PCA UMAP\n",
      "mainExpName: RNA\n",
      "altExpNames(0):\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sce_from_seurat <- Seurat::as.SingleCellExperiment(seurat)\n",
    "sce_from_seurat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "2000 features across 100 samples within 1 assay \n",
      "Active assay: RNA (2000 features, 0 variable features)\n",
      " 2 layers present: counts, data\n",
      " 2 dimensional reductions calculated: PCA, UMAP\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "seurat_from_sce <- Seurat::as.Seurat(sce_from_seurat)\n",
    "seurat_from_sce\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difficult part here is due to the differences between the structures of the two objects.\n",
    "It is important to make sure the arguments are set correctly so that the conversion functions know which information to convert and where to place it.\n",
    "\n",
    "In many cases it may not be necessary to convert a `Seurat` object to a `SingleCellExperiment`.\n",
    "This is because many of the core Bioconductor packages for single-cell analysis have been designed to accept a matrix as input as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 x 10 sparse Matrix of class \"dgCMatrix\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]:   [[ suppressing 10 column names ‘Cell_0’, ‘Cell_1’, ‘Cell_2’ ... ]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      \n",
      "Gene-0 594.0456    .     984.0238  610.329 964.4394 616.4169    .     \n",
      "Gene-1 594.0456 1168.519 622.6029    .     608.7911   .         .     \n",
      "Gene-2   .         .     984.0238    .     608.7911 973.2674 1205.5970\n",
      "Gene-3 594.0456    .     622.6029  610.329 964.4394 616.4169    .     \n",
      "Gene-4 594.0456    .     622.6029  966.820 964.4394   .         .     \n",
      "Gene-5 594.0456  580.157 622.6029  610.329 608.7911   .       601.7422\n",
      "Gene-6   .         .     622.6029  610.329   .      616.4169  601.7422\n",
      "Gene-7 594.0456  580.157 622.6029  966.820 608.7911 616.4169    .     \n",
      "Gene-8 594.0456  580.157   .      1219.608 608.7911 973.2674    .     \n",
      "Gene-9 942.9097    .       .         .     964.4394   .       954.8014\n",
      "                                    \n",
      "Gene-0  576.0808  619.7236  604.3937\n",
      "Gene-1  918.4111 1234.7593  958.4625\n",
      "Gene-2    .       619.7236 1209.8233\n",
      "Gene-3    .       619.7236  958.4625\n",
      "Gene-4  576.0808  979.8761  604.3937\n",
      "Gene-5    .       619.7236  958.4625\n",
      "Gene-6    .      1234.7593    .     \n",
      "Gene-7    .       619.7236  604.3937\n",
      "Gene-8 1162.8180  979.8761  958.4625\n",
      "Gene-9    .      1234.7593    .     \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# Calculate Counts Per Million using the Bioconductor scuttle package\n",
    "# with a matrix in a Seurat object\n",
    "cpm <- scuttle::calculateCPM(Seurat::GetAssayData(seurat, slot = \"counts\"))\n",
    "cpm[1:10, 1:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is important to be sure you are accessing the right information and storing any results in the correct place if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing R from Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python interface to R is provided by the [**rpy2** package](https://rpy2.github.io/doc/latest/html/index.html).\n",
    "This allows you to access R functions and objects from Python.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>FloatMatrix with 200000 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            494.804552\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            494.804552\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            519.750520\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            519.750520\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            0.000000\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.FloatMatrix object at 0x154c0f210> [14]\n",
       "R classes: ('matrix', 'array')\n",
       "[494.804552, 494.804552, 0.000000, 494.804552, ..., 1039.501040, 519.750520, 519.750520, 0.000000]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_mat = adata.layers[\"counts\"].T.toarray()\n",
    "\n",
    "with rpy2.robjects.conversion.localconverter(rpy2.robjects.numpy2ri.converter):\n",
    "    rpy2.robjects.globalenv[\"counts_mat\"] = counts_mat\n",
    "\n",
    "cpm = rpy2.robjects.r(\"scuttle::calculateCPM(counts_mat)\")\n",
    "cpm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Python objects (lists, matrices, `DataFrame`s etc.) can also be passed to R.\n",
    "\n",
    "If you are using a Jupyter notebook (as we are for this book) you can use the IPython magic interface to create cells with native R code (passing objects as required).\n",
    "For example, starting a cell with `%%R -i input -o output` says to take `input` as input, run R code and then return `output` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i counts_mat -o magic_cpm\n",
    "# R code running using IPython magic\n",
    "magic_cpm <- scuttle::calculateCPM(counts_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 494.8045522 ,    0.        , 1027.2213662 , ...,    0.        ,\n",
       "           0.        ,  519.75051975],\n",
       "       [ 494.8045522 , 1445.78313253,  513.6106831 , ...,    0.        ,\n",
       "         499.5004995 ,  519.75051975],\n",
       "       [   0.        ,    0.        , 1027.2213662 , ...,  485.90864917,\n",
       "         499.5004995 ,    0.        ],\n",
       "       ...,\n",
       "       [ 494.8045522 ,    0.        ,  513.6106831 , ...,    0.        ,\n",
       "           0.        ,  519.75051975],\n",
       "       [ 989.6091044 ,  481.92771084,    0.        , ...,    0.        ,\n",
       "         499.5004995 ,  519.75051975],\n",
       "       [2474.02276101,  963.85542169,  513.6106831 , ...,  485.90864917,\n",
       "         999.000999  ,    0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python code accessing the results\n",
    "magic_cpm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the approach you will most commonly see in later chapters.\n",
    "For more information about using **rpy2** please refer to [the documentation](https://rpy2.github.io/doc/latest/html/index.html).\n",
    "\n",
    "To work with single-cell data in this way, the [**anndata2ri** package](https://icb-anndata2ri.readthedocs-hosted.com/en/latest/) is particularly useful.\n",
    "As an extension of **rpy2**, it allows R to recognize `AnnData` objects as `SingleCellExperiment` objects, eliminating unnecessary conversion and enabling seamless execution of R code on Python objects.\n",
    "Additionally, it facilitates the conversion of sparse **scipy** matrices.\n",
    "\n",
    "In this example, in order to pass an `AnnData` object in the Python session to R, we have to first convert it to `SingleCellExperiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rpy2.robjects.conversion.localconverter(anndata2ri.converter):\n",
    "    r_adata = rpy2.robjects.conversion.py2rpy(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can pass it to R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with 6 rows and 3 columns\n",
      "             sum  detected     total\n",
      "       <numeric> <integer> <numeric>\n",
      "Cell_0      2021      1297      2021\n",
      "Cell_1      2075      1314      2075\n",
      "Cell_2      1947      1233      1947\n",
      "Cell_3      1986      1250      1986\n",
      "Cell_4      1987      1255      1987\n",
      "Cell_5      1930      1266      1930\n"
     ]
    }
   ],
   "source": [
    "%%R -i r_adata\n",
    "qc <- scuttle::perCellQCMetrics(r_adata)\n",
    "head(qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you will still run into issues if an object (or part of it) cannot be interfaced correctly (for example if there is an unsupported data type).\n",
    "In that case, you may need to modify your object before it can be accessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Python from R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Python from an R session is similar to accessing R from Python but here the interface is provided by the [**{reticulate}** package](https://rstudio.github.io/reticulate/).\n",
    "Once it is loaded we can access Python functions and objects from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List (26 items)\n",
      "<zip object at 0x15d0dc6c0>\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "reticulate_list <- reticulate::r_to_py(LETTERS)\n",
    "print(reticulate_list)\n",
    "py_builtins <- reticulate::import_builtins()\n",
    "py_builtins$zip(letters, LETTERS)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working in an [RMarkdown](https://rmarkdown.rstudio.com/) or [Quarto](https://quarto.org/) document you can also write native Python chunks using the **{reticulate}** Python engine.\n",
    "When we do this we can use the magic `r` and `py` variables to access objects in the other language (the following code is an example that is not run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "```{r}\n",
    "# An R chunk that accesses a Python object\n",
    "print(py$py_object)\n",
    "```\n",
    "\n",
    "```{python}\n",
    "# A Python chunk that accesses an R object\n",
    "print(r$r_object)\n",
    "```\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike **anndata2ri**, there are no R packages that provide a direct interface for Python to view `SingleCellExperiment` or `Seurat` objects as `AnnData` objects.\n",
    "However, we can still access most parts of an `AnnData` using **{reticulate}** (this code is not run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Print an AnnData object in a Python environment\n",
    "py$adata\n",
    "```\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```\n",
    "```r\n",
    "# Alternatively use the Python anndata package to read a H5AD file\n",
    "anndata <- reticulate::import(\"anndata\")\n",
    "anndata$read_h5ad(h5ad_file)\n",
    "```\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```\n",
    "```r\n",
    "# Access the obs slot, pandas DataFrames are automatically converted to R data.frames\n",
    "head(adata$obs)\n",
    "```\n",
    "```\n",
    "       n_genes_by_counts log1p_n_genes_by_counts total_counts\n",
    "Cell_0              1246                7.128496         1965\n",
    "Cell_1              1262                7.141245         2006\n",
    "Cell_2              1262                7.141245         1958\n",
    "Cell_3              1240                7.123673         1960\n",
    "Cell_4              1296                7.167809         2027\n",
    "Cell_5              1231                7.116394         1898\n",
    "       log1p_total_counts pct_counts_in_top_50_genes\n",
    "Cell_0           7.583756                  10.025445\n",
    "Cell_1           7.604396                   9.521436\n",
    "Cell_2           7.580189                   9.959142\n",
    "Cell_3           7.581210                   9.183673\n",
    "Cell_4           7.614805                   9.718796\n",
    "Cell_5           7.549083                  10.168599\n",
    "       pct_counts_in_top_100_genes pct_counts_in_top_200_genes\n",
    "Cell_0                    17.65903                    30.89059\n",
    "Cell_1                    16.99900                    29.71087\n",
    "Cell_2                    17.62002                    30.28601\n",
    "Cell_3                    16.83673                    30.45918\n",
    "Cell_4                    17.11889                    30.04440\n",
    "Cell_5                    18.07165                    30.29505\n",
    "       pct_counts_in_top_500_genes\n",
    "Cell_0                    61.42494\n",
    "Cell_1                    59.62114\n",
    "Cell_2                    60.92952\n",
    "Cell_3                    61.07143\n",
    "Cell_4                    59.64480\n",
    "Cell_5                    61.48577\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above the R **{anndata}** package provides an R interface for `AnnData` objects but it is not currently used by many analysis packages.\n",
    "\n",
    "For more complex analyses that require working with an entire object, it may be necessary to fully convert an object between R and Python\n",
    " While this approach is not memory-efficient due to data duplication, it grants access to a broader range of packages.\n",
    "\n",
    "The **{zellkonverter}** package provides a function for this conversion.\n",
    "Unlike its function for reading H5AD files, this process uses the standard Python environment rather than a specially created one (code not run).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Convert an AnnData to a SingleCellExperiment\n",
    "sce <- zellkonverter::AnnData2SCE(adata, verbose = TRUE)\n",
    "sce\n",
    "```\n",
    "```\n",
    "✔ uns$hvg$flavor converted [21ms]\n",
    "✔ uns$hvg converted [62ms]\n",
    "✔ uns$log1p converted [22ms]\n",
    "✔ uns$neighbors converted [21ms]\n",
    "✔ uns$pca$params$use_highly_variable converted [22ms]\n",
    "✔ uns$pca$params$zero_center converted [31ms]\n",
    "✔ uns$pca$params converted [118ms]\n",
    "✔ uns$pca$variance converted [17ms]\n",
    "✔ uns$pca$variance_ratio converted [17ms]\n",
    "✔ uns$pca converted [224ms]\n",
    "✔ uns$umap$params$a converted [15ms]\n",
    "✔ uns$umap$params$b converted [17ms]\n",
    "✔ uns$umap$params converted [80ms]\n",
    "✔ uns$umap converted [115ms]\n",
    "✔ uns converted [582ms]\n",
    "✔ Converting uns to metadata ... done\n",
    "✔ X matrix converted to assay [44ms]\n",
    "✔ layers$counts converted [29ms]\n",
    "✔ Converting layers to assays ... done\n",
    "✔ var converted to rowData [37ms]\n",
    "✔ obs converted to colData [23ms]\n",
    "✔ varm$PCs converted [18ms]\n",
    "✔ varm converted [49ms]\n",
    "✔ Converting varm to rowData$varm ... done\n",
    "✔ obsm$X_pca converted [17ms]\n",
    "✔ obsm$X_umap converted [17ms]\n",
    "✔ obsm converted [80ms]\n",
    "✔ Converting obsm to reducedDims ... done\n",
    "ℹ varp is empty and was skipped\n",
    "✔ obsp$connectivities converted [21ms]\n",
    "✔ obsp$distances converted [22ms]\n",
    "✔ obsp converted [89ms]\n",
    "✔ Converting obsp to colPairs ... done\n",
    "✔ SingleCellExperiment constructed [241ms]\n",
    "ℹ Skipping conversion of raw\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "class: SingleCellExperiment\n",
    "dim: 2000 100\n",
    "metadata(5): hvg log1p neighbors pca umap\n",
    "assays(2): X counts\n",
    "rownames(2000): Gene_0 Gene_1 ... Gene_1998 Gene_1999\n",
    "rowData names(11): n_cells_by_counts mean_counts ... dispersions_norm\n",
    "  varm\n",
    "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
    "colData names(8): n_genes_by_counts log1p_n_genes_by_counts ...\n",
    "  pct_counts_in_top_200_genes pct_counts_in_top_500_genes\n",
    "reducedDimNames(2): X_pca X_umap\n",
    "mainExpName: NULL\n",
    "altExpNames(0):\n",
    "```\n",
    "\n",
    "The same can also be done in reverse:\n",
    "\n",
    "```r\n",
    "adata2 <- zellkonverter::SCE2AnnData(sce, verbose = TRUE)\n",
    "adata2\n",
    "```\n",
    "```\n",
    "ℹ Using the 'X' assay as the X matrix\n",
    "✔ Selected X matrix [27ms]\n",
    "✔ assays$X converted to X matrix [38ms]\n",
    "✔ additional assays converted to layers [31ms]\n",
    "✔ rowData$varm converted to varm [15ms]\n",
    "✔ reducedDims converted to obsm [63ms]\n",
    "✔ metadata converted to uns [23ms]\n",
    "ℹ rowPairs is empty and was skipped\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'X_name', 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability for multimodal data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complexity of multimodal data presents additional challenges for interoperability.\n",
    "Both `SingleCellExperiment` (via \"alternative experiments,\" which must share the same column dimension for cells) and `Seurat` (using \"assays\") support multiple modalities.\n",
    "However, `AnnData` is limited to unimodal data.\n",
    "\n",
    "To address this limitation, the `MuData` object (introduced in the [analysis frameworks and tools chapter]({ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>`) was developed as as an extension of `AnnData` for multimodal datasets.\n",
    "The developers have considered interoperability in their design.\n",
    "While the main platform for MuData is Python, the authors have provided the [MuDataSeurat R package](https://pmbio.github.io/MuDataSeurat/) for reading the on-disk H5MU format as `Seurat` objects and the [MuData R package](https://bioconductor.org/packages/MuData/) for doing the same with Bioconductor `MultiAssayExperiment` objects. This official support is very useful but there are still some inconsistencies due to differences between the objects. The MuData authors also provide a [Julia implementation](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) of `AnnData` and `MuData`.\n",
    "\n",
    "Below is an example of reading and writing a small example `MuData` dataset using the Python and R packages.\n",
    "\n",
    "To address this, the `MuData` object—introduced in the [analysis frameworks and tools chapter]({ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>`)—extends `AnnData` for multimodal datasets.\n",
    "Designed with interoperability in mind, `MuData` is primarily a Python-based framework, but the authors have provided the [MuDataSeurat R package](https://pmbio.github.io/MuDataSeurat/).\n",
    "This enables reading the on-disk H5MU format as `Seurat` objects, while the [MuData R package](https://bioconductor.org/packages/MuData/) allows conversion to `MultiAssayExperiment` objects.\n",
    "While this official support is very useful, there are still some inconsistencies due to differences between the objects.\n",
    "The `MuData` authors also provide a [Julia implementation](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) of `AnnData` and `MuData`.\n",
    "\n",
    "Below is an example of reading and writing a small example `MuData` dataset using the Python and R packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seohyon/miniconda3/envs/interoperability/lib/python3.12/site-packages/mudata/_core/mudata.py:1531: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"var\", axis=0, join_common=join_common)\n",
      "/Users/seohyon/miniconda3/envs/interoperability/lib/python3.12/site-packages/mudata/_core/mudata.py:1429: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"obs\", axis=1, join_common=join_common)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuData object with n_obs × n_vars = 1000 × 150\n",
      "  var:\t'dummy_var'\n",
      "  2 modalities\n",
      "    A:\t1000 x 100\n",
      "      obs:\t'dummy_obs'\n",
      "      var:\t'dummy_var'\n",
      "    B:\t1000 x 50\n",
      "      obs:\t'dummy_obs'\n",
      "      var:\t'dummy_var'\n"
     ]
    }
   ],
   "source": [
    "# Read file\n",
    "af_mudata = ln.Artifact.get(\n",
    "    key=\"introduction/interoperability_mdata.h5mu\", is_latest=True\n",
    ")\n",
    "mdata = af_mudata.load()\n",
    "print(mdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bioconductor\n",
    "\n",
    "Read/write from/to a `MultiAssayExperiment` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied to: data/interoperability_mdata.h5mu\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Save MuData file locally for R\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "local_path = af_mudata.cache().path\n",
    "\n",
    "target_path = Path(\"data\") / \"interoperability_mdata.h5mu\"\n",
    "shutil.copy(local_path, target_path)\n",
    "print(f\"File copied to: {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A MultiAssayExperiment object of 2 listed\n",
      " experiments with user-defined names and respective classes.\n",
      " Containing an ExperimentList class object of length 2:\n",
      " [1] A: SingleCellExperiment with 100 rows and 1000 columns\n",
      " [2] B: SingleCellExperiment with 50 rows and 1000 columns\n",
      "Functionality:\n",
      " experiments() - obtain the ExperimentList instance\n",
      " colData() - the primary/phenotype DataFrame\n",
      " sampleMap() - the sample coordination DataFrame\n",
      " `$`, `[`, `[[` - extract colData columns, subset, or experiment\n",
      " *Format() - convert into a long or wide DataFrame\n",
      " assays() - convert ExperimentList to a SimpleList of matrices\n",
      " exportClass() - save data to flat files\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "mae <- MuData::readH5MU(\"data/interoperability_mdata.h5mu\")\n",
    "print(mae)\n",
    "\n",
    "bioc_h5mu_file <- tempfile(fileext = \".h5mu\")\n",
    "MuData::writeH5MU(mae, bioc_h5mu_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seurat\n",
    "\n",
    "Read/write from/to a `Seurat` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "150 features across 1000 samples within 2 assays \n",
      "Active assay: A (100 features, 0 variable features)\n",
      " 2 layers present: counts, data\n",
      " 1 other assay present: B\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "seurat <- MuDataSeurat::ReadH5MU(\"data/interoperability_mdata.h5mu\")\n",
    "print(seurat)\n",
    "\n",
    "seurat_h5mu_file <- tempfile(fileext = \".h5mu\")\n",
    "MuDataSeurat::WriteH5MU(seurat, seurat_h5mu_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability with other languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we briefly list some resources and tools for the interoperability of single-cell data with languages other than R and Python.\n",
    "\n",
    "### Julia\n",
    "\n",
    "- [Muon.jl](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) provides Julia implementations of `AnnData` and `MuData` objects, as well as IO for the H5AD and H5MU formats\n",
    "- [scVI.jl](https://github.com/maren-ha/scVI.jl) provides a Julia implementation of `AnnData` as well as IO for the H5AD format\n",
    "\n",
    "### JavaScript\n",
    "\n",
    "- [Vitessce](http://vitessce.io/) contains loaders from `AnnData` objects stored using the Zarr format\n",
    "- The [kana family](https://github.com/jkanche/kana) supports reading H5AD files and `SingleCellExperiment` objects saved as RDS files\n",
    "\n",
    "### Rust\n",
    "\n",
    "- [anndata-rs](https://github.com/kaizhang/anndata-rs) provides a Rust implementation of AnnData as well as advanced IO support for the H5AD format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seohyon/miniconda3/envs/interoperability/lib/python3.12/site-packages/session_info/main.py:213: UserWarning: The '__version__' attribute is deprecated and will be removed in MarkupSafe 3.1. Use feature detection, or `importlib.metadata.version(\"markupsafe\")`, instead.\n",
      "  mod_version = _find_version(mod.__version__)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "anndata             0.11.3\n",
       "anndata2ri          1.3.2\n",
       "lamindb             1.3.0\n",
       "lamindb_setup       1.3.2\n",
       "mudata              0.3.1\n",
       "numpy               2.1.3\n",
       "rpy2                3.5.11\n",
       "scanpy              1.11.0\n",
       "scipy               1.14.1\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                 11.1.0\n",
       "aiobotocore         2.21.1\n",
       "aiohappyeyeballs    2.6.1\n",
       "aiohttp             3.11.14\n",
       "aioitertools        0.12.0\n",
       "aiosignal           1.3.2\n",
       "annotated_types     0.7.0\n",
       "anyio               NA\n",
       "appdirs             1.4.4\n",
       "appnope             0.1.4\n",
       "argcomplete         NA\n",
       "asgiref             3.8.1\n",
       "asttokens           NA\n",
       "attr                25.3.0\n",
       "bionty              1.1.2\n",
       "botocore            1.37.1\n",
       "certifi             2025.01.31\n",
       "chardet             5.2.0\n",
       "charset_normalizer  3.4.1\n",
       "click               8.1.8\n",
       "colorama            0.4.6\n",
       "comm                0.2.2\n",
       "cycler              0.12.1\n",
       "cython_runtime      NA\n",
       "dateutil            2.9.0.post0\n",
       "debugpy             1.8.13\n",
       "decorator           5.2.1\n",
       "defusedxml          0.7.1\n",
       "deprecation         2.1.0\n",
       "dj_database_url     NA\n",
       "django              5.1.7\n",
       "dotenv              NA\n",
       "executing           2.1.0\n",
       "fastobo             0.13.0\n",
       "filelock            3.17.0\n",
       "frozenlist          1.5.0\n",
       "fsspec              2025.2.0\n",
       "gotrue              2.11.4\n",
       "h11                 0.14.0\n",
       "h2                  4.2.0\n",
       "h5py                3.13.0\n",
       "hpack               4.1.0\n",
       "httpcore            1.0.7\n",
       "httpx               0.28.1\n",
       "hyperframe          6.1.0\n",
       "idna                3.10\n",
       "importlib_metadata  NA\n",
       "ipykernel           6.29.5\n",
       "jedi                0.19.2\n",
       "jinja2              3.1.5\n",
       "jmespath            1.0.1\n",
       "joblib              1.4.2\n",
       "kiwisolver          1.4.8\n",
       "lamin_utils         0.13.11\n",
       "legacy_api_wrap     NA\n",
       "llvmlite            0.44.0\n",
       "markupsafe          3.0.2\n",
       "matplotlib          3.10.0\n",
       "mpl_toolkits        NA\n",
       "multidict           6.2.0\n",
       "mypy_extensions     NA\n",
       "natsort             8.4.0\n",
       "nbproject           0.10.6\n",
       "numba               0.61.0\n",
       "orjson              3.10.15\n",
       "packaging           24.2\n",
       "pandas              2.2.3\n",
       "pandera             0.0.0+dev0\n",
       "parso               0.8.4\n",
       "platformdirs        4.3.6\n",
       "postgrest           0.19.3\n",
       "prompt_toolkit      3.0.50\n",
       "pronto              2.7.0\n",
       "propcache           0.3.0\n",
       "psutil              7.0.0\n",
       "psycopg2            2.9.10 (dt dec pq3 ext lo64)\n",
       "pure_eval           0.2.3\n",
       "pyarrow             19.0.1\n",
       "pydantic            2.10.6\n",
       "pydantic_core       2.27.2\n",
       "pydantic_settings   2.8.1\n",
       "pydev_ipython       NA\n",
       "pydevconsole        NA\n",
       "pydevd              3.2.3\n",
       "pydevd_file_utils   NA\n",
       "pydevd_plugins      NA\n",
       "pydevd_tracing      NA\n",
       "pygments            2.19.1\n",
       "pyparsing           3.2.1\n",
       "pytz                2024.1\n",
       "realtime            2.4.1\n",
       "requests            2.32.3\n",
       "rich                NA\n",
       "rpycall             NA\n",
       "rpytools            NA\n",
       "s3fs                2025.2.0\n",
       "six                 1.17.0\n",
       "sklearn             1.5.2\n",
       "sniffio             1.3.1\n",
       "sqlparse            0.5.3\n",
       "stack_data          0.6.3\n",
       "storage3            0.11.3\n",
       "supabase            2.11.0\n",
       "supafunc            NA\n",
       "threadpoolctl       3.5.0\n",
       "tornado             6.4.2\n",
       "traitlets           5.14.3\n",
       "typeguard           NA\n",
       "typing_extensions   NA\n",
       "typing_inspect      NA\n",
       "tzlocal             NA\n",
       "upath               0.2.6\n",
       "urllib3             1.26.20\n",
       "vscode              NA\n",
       "wcwidth             0.2.13\n",
       "websockets          14.2\n",
       "wrapt               1.17.2\n",
       "yaml                6.0.2\n",
       "yarl                1.18.3\n",
       "zipp                NA\n",
       "zmq                 26.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             9.0.2\n",
       "jupyter_client      8.6.3\n",
       "jupyter_core        5.7.2\n",
       "-----\n",
       "Python 3.12.9 | packaged by conda-forge | (main, Mar  4 2025, 22:45:25) [Clang 18.1.8 ]\n",
       "macOS-15.3.2-x86_64-i386-64bit\n",
       "-----\n",
       "Session information updated at 2025-03-26 14:24\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "─ Session info ───────────────────────────────────────────────────────────────\n",
      " setting  value\n",
      " version  R version 4.3.3 (2024-02-29)\n",
      " os       macOS 15.3.2\n",
      " system   x86_64, darwin13.4.0\n",
      " ui       unknown\n",
      " language (EN)\n",
      " collate  C\n",
      " ctype    UTF-8\n",
      " tz       Europe/Berlin\n",
      " date     2025-03-26\n",
      " pandoc   3.6.3 @ /Users/seohyon/miniconda3/envs/interoperability/bin/pandoc\n",
      " quarto   NA\n",
      "\n",
      "─ Packages ───────────────────────────────────────────────────────────────────\n",
      " package              * version    date (UTC) lib source\n",
      " abind                  1.4-8      2024-09-12 [1] CRAN (R 4.3.3)\n",
      " beachmat               2.18.0     2023-10-24 [1] Bioconductor\n",
      " Biobase              * 2.62.0     2023-10-24 [1] Bioconductor\n",
      " BiocGenerics         * 0.48.1     2023-11-01 [1] Bioconductor\n",
      " BiocParallel           1.36.0     2023-10-24 [1] Bioconductor\n",
      " bit                    4.6.0      2025-03-06 [1] CRAN (R 4.3.3)\n",
      " bit64                  4.6.0-1    2025-01-16 [1] CRAN (R 4.3.3)\n",
      " bitops                 1.0-9      2024-10-03 [1] CRAN (R 4.3.3)\n",
      " cli                    3.6.4      2025-02-13 [1] CRAN (R 4.3.3)\n",
      " cluster                2.1.8      2024-12-11 [1] CRAN (R 4.3.3)\n",
      " codetools              0.2-20     2024-03-31 [1] CRAN (R 4.3.3)\n",
      " colorspace             2.1-1      2024-07-26 [1] CRAN (R 4.3.3)\n",
      " cowplot                1.1.3      2024-01-22 [1] CRAN (R 4.3.3)\n",
      " crayon                 1.5.3      2024-06-20 [1] CRAN (R 4.3.3)\n",
      " data.table             1.17.0     2025-02-22 [1] CRAN (R 4.3.3)\n",
      " DelayedArray           0.28.0     2023-10-24 [1] Bioconductor\n",
      " DelayedMatrixStats     1.24.0     2023-10-24 [1] Bioconductor\n",
      " deldir                 2.0-4      2024-02-28 [1] CRAN (R 4.3.3)\n",
      " digest                 0.6.37     2024-08-19 [1] CRAN (R 4.3.3)\n",
      " dotCall64              1.2        2024-10-04 [1] CRAN (R 4.3.3)\n",
      " dplyr                  1.1.4      2023-11-17 [1] CRAN (R 4.3.3)\n",
      " farver                 2.1.2      2024-05-13 [1] CRAN (R 4.3.3)\n",
      " fastDummies            1.7.5      2025-01-20 [1] CRAN (R 4.3.3)\n",
      " fastmap                1.2.0      2024-05-15 [1] CRAN (R 4.3.3)\n",
      " fitdistrplus           1.2-2      2025-01-07 [1] CRAN (R 4.3.3)\n",
      " future                 1.34.0     2024-07-29 [1] CRAN (R 4.3.3)\n",
      " future.apply           1.11.3     2024-10-27 [1] CRAN (R 4.3.3)\n",
      " generics               0.1.3      2022-07-05 [1] CRAN (R 4.3.3)\n",
      " GenomeInfoDb         * 1.38.1     2023-11-08 [1] Bioconductor\n",
      " GenomeInfoDbData       1.2.11     2025-02-21 [1] Bioconductor\n",
      " GenomicRanges        * 1.54.1     2023-10-29 [1] Bioconductor\n",
      " ggplot2                3.5.1      2024-04-23 [1] CRAN (R 4.3.3)\n",
      " ggrepel                0.9.6      2024-09-07 [1] CRAN (R 4.3.3)\n",
      " ggridges               0.5.6      2024-01-23 [1] CRAN (R 4.3.3)\n",
      " globals                0.16.3     2024-03-08 [1] CRAN (R 4.3.3)\n",
      " glue                   1.8.0      2024-09-30 [1] CRAN (R 4.3.3)\n",
      " goftest                1.2-3      2021-10-07 [1] CRAN (R 4.3.3)\n",
      " gridExtra              2.3        2017-09-09 [1] CRAN (R 4.3.3)\n",
      " gtable                 0.3.6      2024-10-25 [1] CRAN (R 4.3.3)\n",
      " hdf5r                  1.3.12     2025-01-20 [1] CRAN (R 4.3.3)\n",
      " htmltools              0.5.8.1    2024-04-04 [1] CRAN (R 4.3.3)\n",
      " htmlwidgets            1.6.4      2023-12-06 [1] CRAN (R 4.3.3)\n",
      " httpuv                 1.6.15     2024-03-26 [1] CRAN (R 4.3.3)\n",
      " httr                   1.4.7      2023-08-15 [1] CRAN (R 4.3.3)\n",
      " ica                    1.0-3      2022-07-08 [1] CRAN (R 4.3.3)\n",
      " igraph                 2.1.4      2025-01-23 [1] CRAN (R 4.3.3)\n",
      " IRanges              * 2.36.0     2023-10-24 [1] Bioconductor\n",
      " irlba                  2.3.5.1    2022-10-03 [1] CRAN (R 4.3.3)\n",
      " jsonlite               1.9.1      2025-03-03 [1] CRAN (R 4.3.3)\n",
      " KernSmooth             2.23-26    2025-01-01 [1] CRAN (R 4.3.3)\n",
      " later                  1.4.1      2024-11-27 [1] CRAN (R 4.3.3)\n",
      " lattice                0.22-6     2024-03-20 [1] CRAN (R 4.3.3)\n",
      " lazyeval               0.2.2      2019-03-15 [1] CRAN (R 4.3.3)\n",
      " lifecycle              1.0.4      2023-11-07 [1] CRAN (R 4.3.3)\n",
      " listenv                0.9.1      2024-01-29 [1] CRAN (R 4.3.3)\n",
      " lmtest                 0.9-40     2022-03-21 [1] CRAN (R 4.3.3)\n",
      " magrittr               2.0.3      2022-03-30 [1] CRAN (R 4.3.3)\n",
      " MASS                   7.3-60.0.1 2024-01-13 [1] CRAN (R 4.3.3)\n",
      " Matrix               * 1.6-5      2024-01-11 [1] CRAN (R 4.3.3)\n",
      " MatrixGenerics       * 1.14.0     2023-10-24 [1] Bioconductor\n",
      " matrixStats          * 1.5.0      2025-01-07 [1] CRAN (R 4.3.3)\n",
      " mime                   0.12       2021-09-28 [1] CRAN (R 4.3.3)\n",
      " miniUI                 0.1.1.1    2018-05-18 [1] CRAN (R 4.3.3)\n",
      " MuData                 0.99.9     2025-03-13 [1] Bioconductor\n",
      " MuDataSeurat           0.0.0.9000 2025-03-13 [1] Github (PMBio/MuDataSeurat@e34e908)\n",
      " MultiAssayExperiment   1.28.0     2023-10-24 [1] Bioconductor\n",
      " munsell                0.5.1      2024-04-01 [1] CRAN (R 4.3.3)\n",
      " nlme                   3.1-167    2025-01-27 [1] CRAN (R 4.3.3)\n",
      " parallelly             1.42.0     2025-01-30 [1] CRAN (R 4.3.3)\n",
      " patchwork              1.3.0      2024-09-16 [1] CRAN (R 4.3.3)\n",
      " pbapply                1.7-2      2023-06-27 [1] CRAN (R 4.3.3)\n",
      " pillar                 1.10.1     2025-01-07 [1] CRAN (R 4.3.3)\n",
      " pkgconfig              2.0.3      2019-09-22 [1] CRAN (R 4.3.3)\n",
      " plotly                 4.10.4     2024-01-13 [1] CRAN (R 4.3.3)\n",
      " plyr                   1.8.9      2023-10-02 [1] CRAN (R 4.3.3)\n",
      " png                    0.1-8      2022-11-29 [1] CRAN (R 4.3.3)\n",
      " polyclip               1.10-7     2024-07-23 [1] CRAN (R 4.3.3)\n",
      " progressr              0.15.1     2024-11-22 [1] CRAN (R 4.3.3)\n",
      " promises               1.3.2      2024-11-28 [1] CRAN (R 4.3.3)\n",
      " purrr                  1.0.4      2025-02-05 [1] CRAN (R 4.3.3)\n",
      " R6                     2.6.1      2025-02-15 [1] CRAN (R 4.3.3)\n",
      " RANN                   2.6.2      2024-08-25 [1] CRAN (R 4.3.3)\n",
      " RColorBrewer           1.1-3      2022-04-03 [1] CRAN (R 4.3.3)\n",
      " Rcpp                   1.0.14     2025-01-12 [1] CRAN (R 4.3.3)\n",
      " RcppAnnoy              0.0.22     2024-01-23 [1] CRAN (R 4.3.3)\n",
      " RcppHNSW               0.6.0      2024-02-04 [1] CRAN (R 4.3.3)\n",
      " RCurl                  1.98-1.16  2024-07-11 [1] CRAN (R 4.3.3)\n",
      " reshape2               1.4.4      2020-04-09 [1] CRAN (R 4.3.3)\n",
      " reticulate             1.41.0.1   2025-03-09 [1] CRAN (R 4.3.3)\n",
      " rhdf5                  2.46.1     2023-11-29 [1] Bioconductor 3.18 (R 4.3.3)\n",
      " rhdf5filters           1.14.1     2023-11-06 [1] Bioconductor\n",
      " Rhdf5lib               1.24.0     2023-10-24 [1] Bioconductor\n",
      " rlang                  1.1.5      2025-01-17 [1] CRAN (R 4.3.3)\n",
      " ROCR                   1.0-11     2020-05-02 [1] CRAN (R 4.3.3)\n",
      " RSpectra               0.16-2     2024-07-18 [1] CRAN (R 4.3.3)\n",
      " Rtsne                  0.17       2023-12-07 [1] CRAN (R 4.3.3)\n",
      " S4Arrays               1.2.0      2023-10-24 [1] Bioconductor\n",
      " S4Vectors            * 0.40.2     2023-11-23 [1] Bioconductor 3.18 (R 4.3.3)\n",
      " scales                 1.3.0      2023-11-28 [1] CRAN (R 4.3.3)\n",
      " scattermore            1.2        2023-06-12 [1] CRAN (R 4.3.3)\n",
      " sctransform            0.4.1      2023-10-19 [1] CRAN (R 4.3.3)\n",
      " scuttle                1.12.0     2023-10-24 [1] Bioconductor\n",
      " sessioninfo            1.2.3      2025-02-05 [1] CRAN (R 4.3.3)\n",
      " Seurat                 5.2.1      2025-01-24 [1] CRAN (R 4.3.3)\n",
      " SeuratDisk             0.0.0.9021 2025-03-13 [1] Github (mojaveazure/seurat-disk@877d4e1)\n",
      " SeuratObject           5.0.2      2024-05-08 [1] CRAN (R 4.3.3)\n",
      " shiny                  1.10.0     2024-12-14 [1] CRAN (R 4.3.3)\n",
      " SingleCellExperiment * 1.24.0     2023-10-24 [1] Bioconductor\n",
      " sp                     2.2-0      2025-02-01 [1] CRAN (R 4.3.3)\n",
      " spam                   2.11-1     2025-01-20 [1] CRAN (R 4.3.3)\n",
      " SparseArray            1.2.2      2023-11-07 [1] Bioconductor\n",
      " sparseMatrixStats      1.14.0     2023-10-24 [1] Bioconductor\n",
      " spatstat.data          3.1-4      2024-11-15 [1] CRAN (R 4.3.3)\n",
      " spatstat.explore       3.3-4      2025-01-08 [1] CRAN (R 4.3.3)\n",
      " spatstat.geom          3.3-5      2025-01-18 [1] CRAN (R 4.3.3)\n",
      " spatstat.random        3.3-2      2024-09-18 [1] CRAN (R 4.3.3)\n",
      " spatstat.sparse        3.1-0      2024-06-21 [1] CRAN (R 4.3.3)\n",
      " spatstat.univar        3.1-2      2025-03-05 [1] CRAN (R 4.3.3)\n",
      " spatstat.utils         3.1-2      2025-01-08 [1] CRAN (R 4.3.3)\n",
      " stringi                1.8.4      2024-05-06 [1] CRAN (R 4.3.3)\n",
      " stringr                1.5.1      2023-11-14 [1] CRAN (R 4.3.3)\n",
      " SummarizedExperiment * 1.32.0     2023-10-24 [1] Bioconductor\n",
      " survival               3.8-3      2024-12-17 [1] CRAN (R 4.3.3)\n",
      " tensor                 1.5        2012-05-05 [1] CRAN (R 4.3.3)\n",
      " tibble                 3.2.1      2023-03-20 [1] CRAN (R 4.3.3)\n",
      " tidyr                  1.3.1      2024-01-24 [1] CRAN (R 4.3.3)\n",
      " tidyselect             1.2.1      2024-03-11 [1] CRAN (R 4.3.3)\n",
      " uwot                   0.2.3      2025-02-24 [1] CRAN (R 4.3.3)\n",
      " vctrs                  0.6.5      2023-12-01 [1] CRAN (R 4.3.3)\n",
      " viridisLite            0.4.2      2023-05-02 [1] CRAN (R 4.3.3)\n",
      " withr                  3.0.2      2024-10-28 [1] CRAN (R 4.3.3)\n",
      " xtable                 1.8-4      2019-04-21 [1] CRAN (R 4.3.3)\n",
      " XVector                0.42.0     2023-10-24 [1] Bioconductor\n",
      " zlibbioc               1.48.0     2023-10-24 [1] Bioconductor\n",
      " zoo                    1.8-13     2025-02-22 [1] CRAN (R 4.3.3)\n",
      "\n",
      " [1] /Users/seohyon/miniconda3/envs/interoperability/lib/R/library\n",
      " * ── Packages attached to the search path.\n",
      "\n",
      "─ Python configuration ───────────────────────────────────────────────────────\n",
      " python:         /Users/seohyon/miniconda3/envs/interoperability/bin/python\n",
      " libpython:      /Users/seohyon/miniconda3/envs/interoperability/bin/python3.12\n",
      " pythonhome:     /Users/seohyon/miniconda3/envs/interoperability:/Users/seohyon/miniconda3/envs/interoperability\n",
      " version:        3.12.9 | packaged by conda-forge | (main, Mar  4 2025, 22:45:25) [Clang 18.1.8 ]\n",
      " numpy:          /Users/seohyon/miniconda3/envs/interoperability/lib/python3.12/site-packages/numpy\n",
      " numpy_version:  2.1.3\n",
      " \n",
      " NOTE: Python version was forced by the current process\n",
      "\n",
      "──────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sessioninfo::session_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":labelprefix: int\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "We gratefully acknowledge the contributions of:\n",
    "\n",
    "### Authors\n",
    "\n",
    "* Luke Zappia\n",
    "* Seo H. Kim\n",
    "\n",
    "### Reviewers\n",
    "\n",
    "* Lukas Heumos\n",
    "* Isaac Virshup\n",
    "* Anastasia Litinetskaya\n",
    "* Ludwig Geistlinger\n",
    "* Peter Hickey"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interoperability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
